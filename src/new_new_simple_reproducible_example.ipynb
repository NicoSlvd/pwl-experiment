{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01de14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f39729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498831</td>\n",
       "      <td>0.498391</td>\n",
       "      <td>0.496947</td>\n",
       "      <td>0.496930</td>\n",
       "      <td>-1.654070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281851</td>\n",
       "      <td>0.285530</td>\n",
       "      <td>0.291431</td>\n",
       "      <td>0.290942</td>\n",
       "      <td>0.407711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-2.732636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.253412</td>\n",
       "      <td>0.245748</td>\n",
       "      <td>0.245258</td>\n",
       "      <td>0.235843</td>\n",
       "      <td>-1.963428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.500173</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.500059</td>\n",
       "      <td>-1.623297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.743091</td>\n",
       "      <td>0.745965</td>\n",
       "      <td>0.747204</td>\n",
       "      <td>0.750282</td>\n",
       "      <td>-1.383307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998907</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>-0.541356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f0           f1           f2           f3       choice\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000\n",
       "mean      0.498831     0.498391     0.496947     0.496930    -1.654070\n",
       "std       0.281851     0.285530     0.291431     0.290942     0.407711\n",
       "min       0.000036     0.000184     0.000332     0.000037    -2.732636\n",
       "25%       0.253412     0.245748     0.245258     0.235843    -1.963428\n",
       "50%       0.500025     0.500173     0.500075     0.500059    -1.623297\n",
       "75%       0.743091     0.745965     0.747204     0.750282    -1.383307\n",
       "max       0.998907     0.999978     0.999739     0.999854    -0.541356"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from rumboost.metrics import cross_entropy\n",
    "np.random.seed(0)\n",
    "\n",
    "def compute_levels(sp, betas):\n",
    "    levels = np.zeros(len(sp))\n",
    "    for i in range(len(sp) - 1):\n",
    "        levels[i + 1] = levels[i] + (sp[i + 1] - sp[i]) * betas[i]\n",
    "    return levels\n",
    "\n",
    "\n",
    "def create_pw_linear_feature(x, sp, betas, intercept):\n",
    "    indices = np.searchsorted(sp, x) - 1\n",
    "    levels = compute_levels(sp, betas) + intercept\n",
    "    f_x = levels[indices] + betas[indices] * (x - sp[indices])\n",
    "\n",
    "    return f_x\n",
    "\n",
    "\n",
    "def apply_linear_feature(x_arr, sp, betas, feature_names, intercept):\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            feature_names[i]: np.array(\n",
    "                create_pw_linear_feature(x, sp[i], betas[i], intercept[i])\n",
    "            )\n",
    "            for i, x in enumerate(x_arr.T)\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_pw_constant_feature(x, sp, betas, intercept):\n",
    "    indices = np.searchsorted(sp, x) - 1\n",
    "    f_x = betas[indices] + intercept\n",
    "\n",
    "    return f_x\n",
    "\n",
    "def apply_constant_feature(x_arr, sp, betas, feature_names, intercept):\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            feature_names[i]: np.array(\n",
    "                create_pw_constant_feature(x, sp[i], betas[i], intercept[i])\n",
    "            )\n",
    "            for i, x in enumerate(x_arr.T)\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def create_sinusoidal_feature(x, sp, betas, intercept):\n",
    "    indices = np.searchsorted(sp, x) - 1\n",
    "    f_x = np.sin(betas[indices] * x) + intercept\n",
    "    return f_x\n",
    "\n",
    "def apply_sinusoidal_feature(x_arr, sp, betas, feature_names, intercept):\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            feature_names[i]: np.array(\n",
    "                create_sinusoidal_feature(x, sp[i], betas[i], intercept[i])\n",
    "            )\n",
    "            for i, x in enumerate(x_arr.T)\n",
    "        }\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_dataset(x_arr, feature_names):\n",
    "    return pd.DataFrame({feature_names[i]: x_arr[:, i] for i in range(x_arr.shape[1])})\n",
    "\n",
    "\n",
    "def generate_x(n, k, props_low=0.5, cut=0.5, deterministic=False):\n",
    "    n_low = int(props_low * n)\n",
    "    n_high = n - n_low\n",
    "    if deterministic:\n",
    "        x_low = np.linspace([0]*n_utility, [cut]*n_utility, n_low)\n",
    "        x_high = np.linspace([cut]*n_utility, [1]*n_utility, n_high)\n",
    "    else:\n",
    "        x_low = np.random.uniform(0, cut, (n_low, k))\n",
    "        x_high = np.random.uniform(cut, 1, (n_high, k))\n",
    "\n",
    "    return np.concatenate([x_low, x_high], axis=0)\n",
    "\n",
    "\n",
    "def add_choice(row, u_idx, regression=False):\n",
    "    u = np.array([np.sum(row[u_idx[i][0] : u_idx[i][1]]) for i in range(len(u_idx))])\n",
    "    if regression:\n",
    "        return u[0]\n",
    "    else:\n",
    "        return np.random.choice(u.shape[0], size=1, p=softmax(u))[0]\n",
    "\n",
    "n_utility = 1 \n",
    "regression = n_utility == 1\n",
    "f_per_utility = 4\n",
    "x_arr = generate_x(2000, n_utility * f_per_utility, 0.5, 0.5)\n",
    "# x_arr[:, 1] = x_arr[:, 0]\n",
    "# x_arr[:, 2] = x_arr[:, 0]\n",
    "x_arr_test = generate_x(1000, n_utility * f_per_utility, 0.5, 0.5)\n",
    "# x_arr_test[:, 1] = x_arr_test[:, 0]\n",
    "# x_arr_test[:, 2] = x_arr_test[:, 0]\n",
    "sp = np.array(\n",
    "    [\n",
    "        [0, 0.25, 0.5, 0.75, 1],\n",
    "        [0, 0.4, 0.5, 0.6, 1],\n",
    "        [0, 0.3, 0.5, 0.7, 1],\n",
    "        [0, 0.2, 0.4, 0.5, 1],\n",
    "        [0, 0.25, 0.5, 0.75, 1],\n",
    "        [0, 0.4, 0.5, 0.6, 1],\n",
    "        [0, 0.34, 0.5, 0.55, 1],\n",
    "        [0, 0.2, 0.4, 0.8, 1],\n",
    "        [0, 0.1, 0.55, 0.6, 1],\n",
    "        [0, 0.3, 0.5, 0.7, 1],\n",
    "        [0, 0.25, 0.5, 0.75, 1],\n",
    "        [0, 0.4, 0.5, 0.6, 1],\n",
    "        [0, 0.3, 0.5, 0.7, 1],\n",
    "        [0, 0.2, 0.4, 0.5, 1],\n",
    "        [0, 0.25, 0.5, 0.75, 1],\n",
    "        [0, 0.4, 0.5, 0.6, 1],\n",
    "    ]\n",
    ")\n",
    "betas = np.array(\n",
    "    [\n",
    "        [1, 2, 0.5, 1],\n",
    "        [0.5, 0, 0.5, 1],\n",
    "        [-0.5, -0.5, -2, -3],\n",
    "        [0, 0, 0, 0],\n",
    "        [3, -2, 0.5, -1],\n",
    "        [0.5, 0, 0.5, 1],\n",
    "        [-0.5, -0.5, -2, -3],\n",
    "        [0, 1, 1, 0],\n",
    "        [1, -2, 0.5, -1],\n",
    "        [-0.5, 0, 0.5, 1],\n",
    "        [-0.5, -0.5, -2, -3],\n",
    "        [0, 0, 5, 0],\n",
    "        [1, 1, 0.9, -1],\n",
    "        [0.5, -1, 0.5, 1],\n",
    "        [-0.5, -0.5, 2, -3],\n",
    "        [0, -1, 0, 0],\n",
    "    ]\n",
    ")\n",
    "intercept = [-0.5, -1.5, 0.5, -1, 0, -2, 1, -2, 1, -1, -0.5, 0.5, -2, 0, 0, 0.5]\n",
    "\n",
    "ind = [i for i in range(4 * n_utility) if i % 4 < f_per_utility]\n",
    "sp = [sp[i] for i in ind]\n",
    "betas = [betas[i] for i in ind]\n",
    "intercept = [intercept[i] for i in ind]\n",
    "\n",
    "feature_names = [f\"f{i}\" for i in range(f_per_utility*n_utility)]\n",
    "\n",
    "u_idx = [(i * f_per_utility, (i+1) * f_per_utility) for i in range(n_utility)]\n",
    "\n",
    "x_plot = np.linspace(1e-4, 1, 1000).reshape(-1, 1)\n",
    "for i, (sp_i, beta_i, inter_i) in enumerate(zip(sp, betas, intercept)):\n",
    "    if i % 4 == 0:\n",
    "        y_plot = apply_linear_feature(\n",
    "            x_plot, sp_i.reshape(1, -1), beta_i.reshape(1, -1), feature_names, [inter_i]\n",
    "        ).values\n",
    "    elif i % 4 == 1:\n",
    "        y_plot = apply_constant_feature(\n",
    "            x_plot, sp_i.reshape(1, -1), beta_i.reshape(1, -1), feature_names, [inter_i]\n",
    "        ).values\n",
    "    elif i % 4 == 2:\n",
    "        y_plot = apply_sinusoidal_feature(\n",
    "            x_plot, sp_i.reshape(1, -1), beta_i.reshape(1, -1), feature_names, [inter_i]\n",
    "        ).values\n",
    "    else:\n",
    "        y_plot = apply_linear_feature(\n",
    "            x_plot, sp_i.reshape(1, -1), beta_i.reshape(1, -1), feature_names, [inter_i]\n",
    "        ).values\n",
    "    plt.plot(x_plot, y_plot, label=feature_names[i], linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "dataset = create_dataset(x_arr, feature_names)\n",
    "dataset_transf = pd.DataFrame()\n",
    "for i in range(x_arr.shape[1]):\n",
    "    if i % 4 == 0:\n",
    "        dataset_transf.loc[:, feature_names[i]] = apply_linear_feature(\n",
    "            x_arr[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    elif i % 4 == 1:\n",
    "        dataset_transf.loc[:, feature_names[i]] = apply_constant_feature(\n",
    "            x_arr[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    elif i % 4 == 2:\n",
    "        dataset_transf.loc[:, feature_names[i]] = apply_sinusoidal_feature(\n",
    "            x_arr[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    else:\n",
    "        dataset_transf.loc[:, feature_names[i]] = apply_linear_feature(\n",
    "            x_arr[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "\n",
    "dataset[\"choice\"] = dataset_transf.apply(add_choice, axis=1, u_idx=u_idx, regression=regression)\n",
    "dataset_test = create_dataset(x_arr_test, feature_names)\n",
    "dataset_test_transf = pd.DataFrame()\n",
    "for i in range(len(sp)):\n",
    "    if i % 4 == 0:\n",
    "        dataset_test_transf.loc[:, feature_names[i]] = apply_linear_feature(\n",
    "            x_arr_test[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    elif i % 4 == 1:\n",
    "        dataset_test_transf.loc[:, feature_names[i]] = apply_constant_feature(\n",
    "            x_arr_test[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    elif i % 4 == 2:\n",
    "        dataset_test_transf.loc[:, feature_names[i]] = apply_sinusoidal_feature(\n",
    "            x_arr_test[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "    else:\n",
    "        dataset_test_transf.loc[:, feature_names[i]] = apply_linear_feature(\n",
    "            x_arr_test[:,i].reshape(-1,1), sp[i].reshape(1, -1), betas[i].reshape(1, -1), feature_names, [intercept[i]]\n",
    "        )\n",
    "dataset_test[\"choice\"] = dataset_test_transf.apply(add_choice, axis=1, u_idx=u_idx, regression=regression)\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1550dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.357595</td>\n",
       "      <td>0.301382</td>\n",
       "      <td>0.272442</td>\n",
       "      <td>-1.851308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211827</td>\n",
       "      <td>0.322947</td>\n",
       "      <td>0.218794</td>\n",
       "      <td>0.445887</td>\n",
       "      <td>-1.897351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481831</td>\n",
       "      <td>0.191721</td>\n",
       "      <td>0.395863</td>\n",
       "      <td>0.264447</td>\n",
       "      <td>-1.482979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284022</td>\n",
       "      <td>0.462798</td>\n",
       "      <td>0.035518</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>-2.199714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.416310</td>\n",
       "      <td>0.389078</td>\n",
       "      <td>0.435006</td>\n",
       "      <td>-2.683205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.640428</td>\n",
       "      <td>0.777858</td>\n",
       "      <td>0.653853</td>\n",
       "      <td>0.846559</td>\n",
       "      <td>-1.645377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.687838</td>\n",
       "      <td>0.880903</td>\n",
       "      <td>0.741713</td>\n",
       "      <td>0.820135</td>\n",
       "      <td>-1.449529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.963027</td>\n",
       "      <td>0.717672</td>\n",
       "      <td>0.775322</td>\n",
       "      <td>0.594559</td>\n",
       "      <td>-1.140128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.846716</td>\n",
       "      <td>0.606354</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.961592</td>\n",
       "      <td>-1.098407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.970650</td>\n",
       "      <td>0.900914</td>\n",
       "      <td>0.769572</td>\n",
       "      <td>0.918609</td>\n",
       "      <td>-1.144219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f0        f1        f2        f3    choice\n",
       "0     0.274407  0.357595  0.301382  0.272442 -1.851308\n",
       "1     0.211827  0.322947  0.218794  0.445887 -1.897351\n",
       "2     0.481831  0.191721  0.395863  0.264447 -1.482979\n",
       "3     0.284022  0.462798  0.035518  0.043565 -2.199714\n",
       "4     0.010109  0.416310  0.389078  0.435006 -2.683205\n",
       "...        ...       ...       ...       ...       ...\n",
       "1995  0.640428  0.777858  0.653853  0.846559 -1.645377\n",
       "1996  0.687838  0.880903  0.741713  0.820135 -1.449529\n",
       "1997  0.963027  0.717672  0.775322  0.594559 -1.140128\n",
       "1998  0.846716  0.606354  0.844979  0.961592 -1.098407\n",
       "1999  0.970650  0.900914  0.769572  0.918609 -1.144219\n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b89857",
   "metadata": {},
   "source": [
    "## Gradient boosting with linear trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3da0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def compute_preds(X):\n",
    "    preds = softmax(X, axis=1)\n",
    "    return preds\n",
    "\n",
    "def compute_grads_and_hess(preds, labels, num_classes=3):\n",
    "    if num_classes > 1:\n",
    "        grads = preds - labels\n",
    "        factor = num_classes / (num_classes - 1)\n",
    "        hess = factor * preds * (1 - preds)\n",
    "        hess = np.maximum(hess, 1e-6)\n",
    "    else:\n",
    "        grads = 2 *(preds - labels)\n",
    "        hess = 2 * np.ones_like(preds)\n",
    "    return grads, hess\n",
    "\n",
    "\n",
    "def truncate(grads, hess, x, grads_x, hess_x, split, left=True):\n",
    "\n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "\n",
    "\n",
    "    for second_split in np.unique(x):\n",
    "        if second_split == split:\n",
    "            continue\n",
    "        if second_split < 0.05 or second_split > 0.95:\n",
    "            continue\n",
    "        if np.abs(split-second_split) < 0.05:\n",
    "            continue\n",
    "        left_mask = x <= second_split\n",
    "        right_mask = x > second_split\n",
    "        grads_left = grads[left_mask]\n",
    "        hess_left = hess[left_mask]\n",
    "        grads_right = grads[right_mask]\n",
    "        hess_right = hess[right_mask]\n",
    "        grads_x_left = grads_x[left_mask]\n",
    "        hess_x_left = hess_x[left_mask]\n",
    "        grads_x_right = grads_x[right_mask]\n",
    "        hess_x_right = hess_x[right_mask]\n",
    "\n",
    "        if left:\n",
    "            beta = - grads_x_right.sum() / hess_x_right.sum()\n",
    "            new_gain = (grads_x_right ** 2).sum() / hess_x_right.sum() - (grads_x**2).sum()/hess_x.sum() #+ np.sum(grads_left * beta * (second_split-split)) + 0.5 * np.sum(hess_left * beta ** 2 * (second_split - split) ** 2)\n",
    "        else:\n",
    "            beta = - grads_x_left.sum() / hess_x_left.sum()\n",
    "            new_gain = (grads_x_left ** 2).sum() / hess_x_left.sum() - (grads_x**2).sum()/hess_x.sum() # + np.sum(grads_right * beta * (second_split-split)) + 0.5 * np.sum(hess_right * beta ** 2 * (second_split - split) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "        if new_gain > best_gain:\n",
    "            best_gain = new_gain\n",
    "            best_split = second_split\n",
    "\n",
    "    if best_gain == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        return best_split, best_gain\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def compute_split_gain(grads, hess, split, feature, one_sided=False, grads_x=None, hess_x=None, from_split_point=False):\n",
    "    left_mask = feature <= split\n",
    "    right_mask = feature > split\n",
    "    left_grads = grads[left_mask]\n",
    "    right_grads = grads[right_mask]\n",
    "    left_hess = hess[left_mask]\n",
    "    right_hess = hess[right_mask]\n",
    "    if grads_x is not None and hess_x is not None:\n",
    "        left_grads_x = grads_x[left_mask]\n",
    "        right_grads_x = grads_x[right_mask]\n",
    "        left_hess_x = hess_x[left_mask]\n",
    "        right_hess_x = hess_x[right_mask]\n",
    "        \n",
    "        no_split_gain = np.sum(grads_x) ** 2 / np.sum(hess_x)\n",
    "        left_gain = np.sum(left_grads_x) ** 2 / np.sum(left_hess_x)\n",
    "        right_gain = np.sum(right_grads_x) ** 2 / np.sum(right_hess_x)\n",
    "        if split < 0.05 or split > 0.95:\n",
    "            left_gain_x = 0\n",
    "            right_gain_x = 0\n",
    "        else:\n",
    "            if not from_split_point:\n",
    "                beta_l = - np.sum(left_grads_x) / np.sum(left_hess_x)\n",
    "                right_gain_x = np.sum(right_grads * beta_l * split) + 0.5 * np.sum(right_hess * beta_l ** 2 * split ** 2)\n",
    "                left_gain = left_gain + right_gain_x\n",
    "                beta_r = - np.sum(right_grads_x) / np.sum(right_hess_x)\n",
    "                left_gain_x = np.sum(left_grads * beta_r * split) + 0.5 * np.sum(left_hess * beta_r ** 2 * split ** 2)\n",
    "                right_gain = right_gain + left_gain_x\n",
    "    else:\n",
    "        no_split_gain = np.sum(grads) ** 2 / np.sum(hess)\n",
    "        left_gain = np.sum(left_grads) ** 2 / np.sum(left_hess)\n",
    "        right_gain = np.sum(right_grads) ** 2 / np.sum(right_hess)\n",
    "\n",
    "    bigger_gain_left = left_gain > right_gain\n",
    "\n",
    "    if one_sided:\n",
    "        if bigger_gain_left:\n",
    "            if from_split_point:\n",
    "                right_gain = left_gain_x\n",
    "            else:\n",
    "                right_gain = 0\n",
    "        else:\n",
    "            if from_split_point:\n",
    "                left_gain = right_gain_x\n",
    "            else:\n",
    "                left_gain = 0\n",
    "    gain = left_gain + right_gain - no_split_gain\n",
    "    return gain, bigger_gain_left\n",
    "\n",
    "def find_best_split(X, grads, hess, linear_trees=False, from_split_point=False):\n",
    "    best_gain = -np.inf\n",
    "    best_split = None\n",
    "    best_feature = None\n",
    "    best_bigger_gain_left = None\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    for feature in range(X.shape[1]):\n",
    "        unique_values = np.unique(X[:, feature])\n",
    "        for split in unique_values:\n",
    "            if linear_trees and from_split_point:\n",
    "                grads_ = grads * (X[:, feature] - split)\n",
    "                hess_ = hess * (X[:, feature] - split)**2\n",
    "                one_sided = False\n",
    "            elif linear_trees:\n",
    "                grads_ = grads * (X[:, feature])\n",
    "                hess_ = hess * (X[:, feature])**2\n",
    "                one_sided = True\n",
    "            else:\n",
    "                grads_ = None\n",
    "                hess_ = None \n",
    "                one_sided = False\n",
    "            gain, bigger_gain_left = compute_split_gain(grads, hess, split, X[:, feature], one_sided=one_sided, grads_x=grads_, hess_x=hess_, from_split_point=from_split_point)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = copy.deepcopy(gain)\n",
    "                best_split = copy.deepcopy(split)\n",
    "                best_feature = copy.deepcopy(feature)\n",
    "                best_bigger_gain_left = copy.deepcopy(bigger_gain_left)\n",
    "        \n",
    "\n",
    "    return best_feature, best_split, best_gain, best_bigger_gain_left\n",
    "\n",
    "def compute_leaf_value(grads, hess, feature, split, linear_trees=False, from_split_point=False, second_split_left=None, second_split_right=None):\n",
    "    no_split_value = - np.sum(grads) / np.sum(hess)\n",
    "    left_mask = feature <= split\n",
    "    right_mask = feature > split\n",
    "\n",
    "    if linear_trees and from_split_point:\n",
    "        grads = grads * (feature - split)\n",
    "        hess = hess * (feature - split)**2\n",
    "        if second_split_left:\n",
    "            grads = grads * ((feature - split) >= (second_split_left - split))\n",
    "            hess = hess * ((feature - split) >= (second_split_left - split))\n",
    "        if second_split_right:\n",
    "            grads = grads * ((feature - split) < (second_split_right - split))\n",
    "            hess = hess * ((feature-split) < (second_split_right - split))\n",
    "    elif linear_trees:\n",
    "        grads = grads * (feature)\n",
    "        hess = hess * (feature)**2\n",
    "\n",
    "    \n",
    "    left_grads = grads[left_mask]\n",
    "    right_grads = grads[right_mask]\n",
    "    left_hess = hess[left_mask]\n",
    "    right_hess = hess[right_mask]\n",
    "\n",
    "    left_value = - np.sum(left_grads) / np.sum(left_hess)\n",
    "    right_value = - np.sum(right_grads) / np.sum(right_hess)\n",
    "\n",
    "    return left_value, right_value, no_split_value\n",
    "\n",
    "def boost(X, y, preds, num_classes=3, linear_trees=False, from_split_point=False):\n",
    "    grads, hess = compute_grads_and_hess(preds, y, num_classes=num_classes)\n",
    "    feature, split, gain, bigger_left = find_best_split(X, grads, hess, linear_trees=linear_trees, from_split_point=from_split_point)\n",
    "    if linear_trees and from_split_point:\n",
    "        left_grads = grads[X[:, feature] <= split]\n",
    "        left_hess = hess[X[:, feature] <= split]\n",
    "        left_grads_x = left_grads * (X[X[:, feature] <= split, feature] - split)\n",
    "        left_hess_x = left_hess * (X[X[:, feature] <= split, feature] - split)**2\n",
    "        second_split_left, gain_left = truncate(left_grads, left_hess, x=X[X[:, feature] <= split,feature], grads_x=left_grads_x, hess_x=left_hess_x, split=split, left=True)\n",
    "       \n",
    "        right_grads = grads[X[:, feature] > split]\n",
    "        right_hess = hess[X[:, feature] > split]\n",
    "        right_grads_x = right_grads * (X[X[:, feature] > split, feature] - split)\n",
    "        right_hess_x = right_hess * (X[X[:, feature] > split, feature] - split)**2\n",
    "        second_split_right, gain_right = truncate(right_grads, right_hess, x=X[X[:, feature] > split,feature], grads_x=right_grads_x, hess_x=right_hess_x, split=split, left=False)\n",
    "\n",
    "        if second_split_left:\n",
    "            gain += gain_left\n",
    "        \n",
    "        if second_split_right:\n",
    "            gain += gain_right\n",
    "\n",
    "    left_value, right_value, no_split_value = compute_leaf_value(grads, hess, X[:, feature].reshape(-1), split, linear_trees=linear_trees, from_split_point=from_split_point, second_split_left=second_split_left, second_split_right = second_split_right)\n",
    "\n",
    "    return feature, split, left_value, right_value, gain, no_split_value, bigger_left, second_split_left, second_split_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def compute_preds(X):\n",
    "    preds = softmax(X, axis=1)\n",
    "    return preds\n",
    "\n",
    "def compute_grads_and_hess(preds, labels, num_classes=3):\n",
    "    if num_classes > 1:\n",
    "        grads = preds - labels\n",
    "        factor = num_classes / (num_classes - 1)\n",
    "        hess = factor * preds * (1 - preds)\n",
    "        hess = np.maximum(hess, 1e-6)\n",
    "    else:\n",
    "        grads = 2 *(preds - labels)\n",
    "        hess = 2 * np.ones_like(preds)\n",
    "    return grads, hess\n",
    "\n",
    "\n",
    "def truncate(grads, hess, x, grads_x, hess_x, split, left=True):\n",
    "\n",
    "    best_gain = 0\n",
    "    best_split = None\n",
    "\n",
    "\n",
    "    for second_split in np.unique(x):\n",
    "        if second_split == split:\n",
    "            continue\n",
    "        if second_split < 0.05 or second_split > 0.95:\n",
    "            continue\n",
    "        if np.abs(split-second_split) < 0.05:\n",
    "            continue\n",
    "        left_mask = x <= second_split\n",
    "        right_mask = x > second_split\n",
    "        grads_left = grads[left_mask]\n",
    "        hess_left = hess[left_mask]\n",
    "        grads_right = grads[right_mask]\n",
    "        hess_right = hess[right_mask]\n",
    "        grads_x_left = grads_x[left_mask]\n",
    "        hess_x_left = hess_x[left_mask]\n",
    "        grads_x_right = grads_x[right_mask]\n",
    "        hess_x_right = hess_x[right_mask]\n",
    "\n",
    "        if left:\n",
    "            new_gain = (grads_x_right ** 2).sum() / hess_x_right.sum() + (grads_x_left**2).sum() / hess_x_left.sum() - (grads_x**2).sum()/hess_x.sum() \n",
    "        else:\n",
    "            new_gain = (grads_x_left ** 2).sum() / hess_x_left.sum() + (grads_x_right ** 2).sum() / hess_x_right.sum() - (grads_x**2).sum()/hess_x.sum() # + np.sum(grads_right * beta * (second_split-split)) + 0.5 * np.sum(hess_right * beta ** 2 * (second_split - split) ** 2)\n",
    "\n",
    "\n",
    "\n",
    "        if new_gain > best_gain:\n",
    "            best_gain = new_gain\n",
    "            best_split = second_split\n",
    "\n",
    "    if best_gain == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        return best_split, best_gain\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def compute_split_gain(grads, hess, split, feature, one_sided=False, grads_x=None, hess_x=None, from_split_point=False):\n",
    "    left_mask = feature <= split\n",
    "    right_mask = feature > split\n",
    "    left_grads = grads[left_mask]\n",
    "    right_grads = grads[right_mask]\n",
    "    left_hess = hess[left_mask]\n",
    "    right_hess = hess[right_mask]\n",
    "    if grads_x is not None and hess_x is not None:\n",
    "        left_grads_x = grads_x[left_mask]\n",
    "        right_grads_x = grads_x[right_mask]\n",
    "        left_hess_x = hess_x[left_mask]\n",
    "        right_hess_x = hess_x[right_mask]\n",
    "        \n",
    "        no_split_gain = np.sum(grads_x) ** 2 / np.sum(hess_x)\n",
    "        left_gain = np.sum(left_grads_x) ** 2 / np.sum(left_hess_x)\n",
    "        right_gain = np.sum(right_grads_x) ** 2 / np.sum(right_hess_x)\n",
    "        if split < 0.05 or split > 0.95:\n",
    "            left_gain_x = 0\n",
    "            right_gain_x = 0\n",
    "        else:\n",
    "            if not from_split_point:\n",
    "                beta_l = - np.sum(left_grads_x) / np.sum(left_hess_x)\n",
    "                right_gain_x = np.sum(right_grads * beta_l * split) + 0.5 * np.sum(right_hess * beta_l ** 2 * split ** 2)\n",
    "                left_gain = left_gain + right_gain_x\n",
    "                beta_r = - np.sum(right_grads_x) / np.sum(right_hess_x)\n",
    "                left_gain_x = np.sum(left_grads * beta_r * split) + 0.5 * np.sum(left_hess * beta_r ** 2 * split ** 2)\n",
    "                right_gain = right_gain + left_gain_x\n",
    "    else:\n",
    "        no_split_gain = np.sum(grads) ** 2 / np.sum(hess)\n",
    "        left_gain = np.sum(left_grads) ** 2 / np.sum(left_hess)\n",
    "        right_gain = np.sum(right_grads) ** 2 / np.sum(right_hess)\n",
    "\n",
    "    bigger_gain_left = left_gain > right_gain\n",
    "\n",
    "    if one_sided:\n",
    "        if bigger_gain_left:\n",
    "            if from_split_point:\n",
    "                right_gain = left_gain_x\n",
    "            else:\n",
    "                right_gain = 0\n",
    "        else:\n",
    "            if from_split_point:\n",
    "                left_gain = right_gain_x\n",
    "            else:\n",
    "                left_gain = 0\n",
    "    gain = left_gain + right_gain - no_split_gain\n",
    "    return gain, bigger_gain_left\n",
    "\n",
    "def find_best_split(X, grads, hess, linear_trees=False, from_split_point=False):\n",
    "    best_gain = -np.inf\n",
    "    best_split = None\n",
    "    best_feature = None\n",
    "    best_bigger_gain_left = None\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    for feature in range(X.shape[1]):\n",
    "        unique_values = np.unique(X[:, feature])\n",
    "        for split in unique_values:\n",
    "            if linear_trees and from_split_point:\n",
    "                grads_ = grads * (X[:, feature] - split)\n",
    "                hess_ = hess * (X[:, feature] - split)**2\n",
    "                one_sided = False\n",
    "            elif linear_trees:\n",
    "                grads_ = grads * (X[:, feature])\n",
    "                hess_ = hess * (X[:, feature])**2\n",
    "                one_sided = True\n",
    "            else:\n",
    "                grads_ = None\n",
    "                hess_ = None \n",
    "                one_sided = False\n",
    "            gain, bigger_gain_left = compute_split_gain(grads, hess, split, X[:, feature], one_sided=one_sided, grads_x=grads_, hess_x=hess_, from_split_point=from_split_point)\n",
    "\n",
    "            if gain > best_gain:\n",
    "                best_gain = copy.deepcopy(gain)\n",
    "                best_split = copy.deepcopy(split)\n",
    "                best_feature = copy.deepcopy(feature)\n",
    "                best_bigger_gain_left = copy.deepcopy(bigger_gain_left)\n",
    "        \n",
    "\n",
    "    return best_feature, best_split, best_gain, best_bigger_gain_left\n",
    "\n",
    "def compute_leaf_value(grads, hess, feature, split, linear_trees=False, from_split_point=False, second_split_left=None, second_split_right=None):\n",
    "    no_split_value = - np.sum(grads) / np.sum(hess)\n",
    "    left_mask = feature <= split\n",
    "    right_mask = feature > split\n",
    "\n",
    "    if linear_trees and from_split_point:\n",
    "        grads = grads * (feature - split)\n",
    "        hess = hess * (feature - split)**2\n",
    "        if second_split_left:\n",
    "            grads = grads * ((feature - split) >= (second_split_left - split))\n",
    "            hess = hess * ((feature - split) >= (second_split_left - split))\n",
    "        if second_split_right:\n",
    "            grads = grads * ((feature - split) < (second_split_right - split))\n",
    "            hess = hess * ((feature-split) < (second_split_right - split))\n",
    "    elif linear_trees:\n",
    "        grads = grads * (feature)\n",
    "        hess = hess * (feature)**2\n",
    "\n",
    "    \n",
    "    left_grads = grads[left_mask]\n",
    "    right_grads = grads[right_mask]\n",
    "    left_hess = hess[left_mask]\n",
    "    right_hess = hess[right_mask]\n",
    "\n",
    "    left_value = - np.sum(left_grads) / np.sum(left_hess)\n",
    "    right_value = - np.sum(right_grads) / np.sum(right_hess)\n",
    "\n",
    "    return left_value, right_value, no_split_value\n",
    "\n",
    "def boost(X, y, preds, num_classes=3, linear_trees=False, from_split_point=False):\n",
    "    grads, hess = compute_grads_and_hess(preds, y, num_classes=num_classes)\n",
    "    feature, split, gain, bigger_left = find_best_split(X, grads, hess, linear_trees=linear_trees, from_split_point=from_split_point)\n",
    "    if linear_trees and from_split_point:\n",
    "        left_grads = grads[X[:, feature] <= split]\n",
    "        left_hess = hess[X[:, feature] <= split]\n",
    "        left_grads_x = left_grads * (X[X[:, feature] <= split, feature] - split)\n",
    "        left_hess_x = left_hess * (X[X[:, feature] <= split, feature] - split)**2\n",
    "        second_split_left, gain_left = truncate(left_grads, left_hess, x=X[X[:, feature] <= split,feature], grads_x=left_grads_x, hess_x=left_hess_x, split=split, left=True)\n",
    "       \n",
    "        right_grads = grads[X[:, feature] > split]\n",
    "        right_hess = hess[X[:, feature] > split]\n",
    "        right_grads_x = right_grads * (X[X[:, feature] > split, feature] - split)\n",
    "        right_hess_x = right_hess * (X[X[:, feature] > split, feature] - split)**2\n",
    "        second_split_right, gain_right = truncate(right_grads, right_hess, x=X[X[:, feature] > split,feature], grads_x=right_grads_x, hess_x=right_hess_x, split=split, left=False)\n",
    "\n",
    "        if second_split_left:\n",
    "            gain += gain_left\n",
    "        \n",
    "        if second_split_right:\n",
    "            gain += gain_right\n",
    "\n",
    "    left_value, right_value, no_split_value = compute_leaf_value(grads, hess, X[:, feature].reshape(-1), split, linear_trees=linear_trees, from_split_point=from_split_point, second_split_left=second_split_left, second_split_right = second_split_right)\n",
    "\n",
    "    return feature, split, left_value, right_value, gain, no_split_value, bigger_left, second_split_left, second_split_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b92a84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self, linear_trees=False, from_split_point=False):\n",
    "        self.linear_trees = linear_trees\n",
    "        self.from_split_point = from_split_point\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y, preds, num_classes=3):\n",
    "        self.tree = self._build_tree(X, y, preds, num_classes=num_classes)\n",
    "\n",
    "    def _build_tree(self, X, y, preds, num_classes=3):\n",
    "\n",
    "        feature, split, left_value, right_value, gain, no_split_value, bigger_left, second_split_left, second_split_right = boost(X, y, preds, num_classes=num_classes, linear_trees=self.linear_trees, from_split_point=self.from_split_point)\n",
    "        if gain <= 0:\n",
    "            return None\n",
    "        \n",
    "        if self.linear_trees and not self.from_split_point:\n",
    "            if bigger_left:\n",
    "                right_value = 0\n",
    "            else:\n",
    "                left_value = 0\n",
    "\n",
    "        return {\n",
    "            \"feature\": feature,\n",
    "            \"split\": split,\n",
    "            \"left_value\": left_value if (self.linear_trees and not self.from_split_point) else left_value,\n",
    "            # \"left_value\": left_value,\n",
    "            \"right_value\": right_value,\n",
    "            \"gain\": gain,\n",
    "            \"left_constant\": split * right_value  if not self.from_split_point else None,\n",
    "            # \"left_constant\": split * right_value + no_split_value if not self.from_split_point else None,\n",
    "            \"right_constant\": split * left_value if not self.from_split_point else None,\n",
    "            # \"right_constant\": split * -left_value + no_split_value if not self.from_split_point else None,\n",
    "            \"second_split_left\": second_split_left,\n",
    "            \"second_split_right\": second_split_right,\n",
    "            \"full_intercept\": no_split_value,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86a4242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    def __init__(self, linear_trees=False, from_split_point=False):\n",
    "        self.linear_trees = linear_trees\n",
    "        self.from_split_point = from_split_point\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y, preds, num_classes=3):\n",
    "        tree = Tree(linear_trees=self.linear_trees, from_split_point=self.from_split_point)\n",
    "        tree.fit(X, y, preds, num_classes=num_classes)\n",
    "        self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.zeros((X.shape[0]))\n",
    "        for tree in self.trees:\n",
    "            if tree.tree is not None:\n",
    "                split = tree.tree[\"split\"]\n",
    "                feature = tree.tree[\"feature\"]\n",
    "                left_value = tree.tree[\"left_value\"]\n",
    "                right_value = tree.tree[\"right_value\"]\n",
    "                left_constant = tree.tree[\"left_constant\"]\n",
    "                right_constant = tree.tree[\"right_constant\"]\n",
    "                second_split_left = tree.tree[\"second_split_left\"]\n",
    "                second_split_right = tree.tree[\"second_split_right\"]\n",
    "                full_intercept = tree.tree[\"full_intercept\"]\n",
    "\n",
    "                x_f = X[:, feature]\n",
    "                if second_split_left is None:\n",
    "                    second_split_left = x_f.min()\n",
    "                if second_split_right is None:\n",
    "                    second_split_right = x_f.max()\n",
    "\n",
    "                if self.linear_trees and self.from_split_point:\n",
    "                    # preds[x_f <= split] += left_value * (x_f[x_f <= split] - split)\n",
    "                    # preds[x_f > split] += right_value * (x_f[x_f > split] - split) \n",
    "                    preds[x_f <= split] += left_value * np.maximum(x_f[x_f <= split] - split, second_split_left - split)\n",
    "                    preds[x_f > split] += right_value * np.minimum(x_f[x_f > split] - split, second_split_right - split)\n",
    "                elif self.linear_trees:\n",
    "                    # preds[x_f <= split] += left_value * x_f[x_f <= split] - left_constant + full_intercept\n",
    "                    # preds[x_f <= split] += left_value * x_f[x_f <= split] + right_constant + full_intercept\n",
    "                    preds[x_f <= split] += left_value * x_f[x_f <= split] + right_constant \n",
    "                    # preds[x_f <= split] += left_value * x_f[x_f <= split] \n",
    "                    # preds[x_f > split] += right_value * x_f[x_f > split] - right_constant + full_intercept\n",
    "                    # preds[x_f > split] += right_value * x_f[x_f > split] + left_constant + full_intercept\n",
    "                    preds[x_f > split] += right_value * x_f[x_f > split] + left_constant \n",
    "                    # preds = preds - left_constant - right_constant + full_intercept\n",
    "                    # preds = preds - left_constant - right_constant - full_intercept\n",
    "                    # preds[x_f > split] += right_value * x_f[x_f > split] \n",
    "                else:\n",
    "                    preds[x_f <= split] += left_value\n",
    "                    preds[x_f > split] += right_value\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19139cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostingModel:\n",
    "    def __init__(self, n_estimators=10, learning_rate=0.1, num_classes=3, linear_trees=False, from_split_point=False, feature_indices=None):\n",
    "        self.linear_trees = linear_trees\n",
    "        self.from_split_point = from_split_point\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.ensemble = [Ensemble(linear_trees=self.linear_trees, from_split_point=self.from_split_point) for _ in range(num_classes)]\n",
    "        self.feature_indices = feature_indices\n",
    "        if self.feature_indices is None:\n",
    "            self.feature_indices = [(i, i+1) for i in range(num_classes)]\n",
    "\n",
    "    def fit(self, X, y, X_test=None, y_test=None):\n",
    "        self.initial_preds = np.zeros((1, self.num_classes))\n",
    "        if self.num_classes > 1:\n",
    "            for j in range(self.num_classes):\n",
    "                self.initial_preds[:, j] = np.log(np.mean(y==j))\n",
    "            raw_preds = np.zeros((X.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "            preds = softmax(raw_preds, axis=1)\n",
    "            print(\"Initial train cel:\", cross_entropy(preds, y))\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_preds = np.zeros((X_test.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "                test_preds = softmax(test_preds, axis=1)\n",
    "                print(\"Initial test cel:\", cross_entropy(test_preds, y_test))\n",
    "        else:\n",
    "            self.initial_preds[:, 0] = np.mean(y)\n",
    "            raw_preds = np.zeros((X.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "            preds = raw_preds\n",
    "            print(\"Initial train mse:\", np.mean((preds - y.reshape(-1, 1))**2))\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_preds = np.zeros((X_test.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "                print(\"Initial test mse:\", np.mean((test_preds - y_test.reshape(-1, 1))**2))\n",
    "            \n",
    "        for i in range(self.n_estimators):\n",
    "            raw_preds = np.zeros((X.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "            for j in range(self.num_classes):\n",
    "                ensemble = self.ensemble[j]\n",
    "                target = y == j if self.num_classes > 1 else y\n",
    "                ensemble.fit(X[:, self.feature_indices[j][0]:self.feature_indices[j][1]], target, preds[:, j], num_classes=self.num_classes)\n",
    "                raw_preds[:, j] += self.learning_rate * ensemble.predict(X[:, self.feature_indices[j][0]:self.feature_indices[j][1]])\n",
    "            if self.num_classes > 1:\n",
    "                preds = softmax(raw_preds, axis=1)\n",
    "                print(\"Train cel:\", cross_entropy(preds, y))\n",
    "            else:\n",
    "                preds = raw_preds\n",
    "                print(\"Train mse:\", np.mean((preds - y.reshape(-1, 1))**2))\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                raw_test_preds = np.zeros((X_test.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "                for j in range(self.num_classes):\n",
    "                    ensemble = self.ensemble[j]\n",
    "                    raw_test_preds[:, j] += self.learning_rate * ensemble.predict(X_test[:, self.feature_indices[j][0]:self.feature_indices[j][1]])\n",
    "                if self.num_classes > 1:\n",
    "                    test_preds = softmax(raw_test_preds, axis=1)\n",
    "                    print(\"Test cel:\", cross_entropy(test_preds, y_test))\n",
    "                else:\n",
    "                    test_preds = raw_test_preds\n",
    "                    print(\"Test mse:\", np.mean((test_preds - y_test.reshape(-1, 1))**2))\n",
    "\n",
    "    def predict(self, X, utilities=False):\n",
    "        preds = np.zeros((X.shape[0], self.num_classes)) + self.initial_preds.copy()\n",
    "\n",
    "        for j in range(self.num_classes):\n",
    "            ensemble = self.ensemble[j]\n",
    "            preds[:, j] += self.learning_rate * ensemble.predict(X[:, self.feature_indices[j][0]:self.feature_indices[j][1]])\n",
    "\n",
    "        return softmax(preds, axis=1) if not utilities else preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be58d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train mse: 0.16614544829406014\n",
      "Initial test mse: 0.1711286158436632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_736573/2990325030.py:77: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  left_gain = np.sum(left_grads_x) ** 2 / np.sum(left_hess_x)\n",
      "/tmp/ipykernel_736573/2990325030.py:78: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  right_gain = np.sum(right_grads_x) ** 2 / np.sum(right_hess_x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mse: 0.14968197849909065\n",
      "Test mse: 0.1543564883836541\n",
      "Train mse: 0.13629616768004643\n",
      "Test mse: 0.1407645148709696\n",
      "Train mse: 0.12548930257691857\n",
      "Test mse: 0.12981960181539687\n",
      "Train mse: 0.11673775830840413\n",
      "Test mse: 0.1209772477023995\n",
      "Train mse: 0.10967183728687425\n",
      "Test mse: 0.1138524957203443\n",
      "Train mse: 0.10382027588108836\n",
      "Test mse: 0.10797658667673088\n",
      "Train mse: 0.09197148827002909\n",
      "Test mse: 0.09612730271143609\n",
      "Train mse: 0.08414724654437376\n",
      "Test mse: 0.08826414310315174\n",
      "Train mse: 0.0878690609045467\n",
      "Test mse: 0.09190697713472418\n",
      "Train mse: 0.09391267023988732\n",
      "Test mse: 0.09780544879291947\n",
      "Train mse: 0.10286061581770715\n",
      "Test mse: 0.10663648152893063\n",
      "Train mse: 0.10352861188122693\n",
      "Test mse: 0.10730113399587562\n",
      "Train mse: 0.1041835267024719\n",
      "Test mse: 0.10795402052283302\n",
      "Train mse: 0.10477762777410116\n",
      "Test mse: 0.10854628556943018\n",
      "Train mse: 0.10531610770189956\n",
      "Test mse: 0.10908310452095935\n",
      "Train mse: 0.10580380869721709\n",
      "Test mse: 0.10956930370910488\n",
      "Train mse: 0.10366019831566188\n",
      "Test mse: 0.10747532172829537\n",
      "Train mse: 0.10399758332325687\n",
      "Test mse: 0.1078031098537152\n",
      "Train mse: 0.10435334337601244\n",
      "Test mse: 0.10815121045193817\n",
      "Train mse: 0.10468394097159085\n",
      "Test mse: 0.10847500193474435\n",
      "Train mse: 0.10500762484314051\n",
      "Test mse: 0.10879301317001637\n",
      "Train mse: 0.10531566307412799\n",
      "Test mse: 0.10909622061902345\n",
      "Train mse: 0.10568925513494108\n",
      "Test mse: 0.10946748188647813\n",
      "Train mse: 0.10602718886705116\n",
      "Test mse: 0.10980330985057628\n",
      "Train mse: 0.10377422444810173\n",
      "Test mse: 0.10759772241804273\n",
      "Train mse: 0.10401931071880031\n",
      "Test mse: 0.1078334235649217\n",
      "Train mse: 0.10426513387919309\n",
      "Test mse: 0.10807120023265333\n",
      "Train mse: 0.10453608934936098\n",
      "Test mse: 0.10833591680598098\n",
      "Train mse: 0.10478865745331965\n",
      "Test mse: 0.10858297017794427\n",
      "Train mse: 0.10502920422126459\n",
      "Test mse: 0.10881876915415785\n",
      "Train mse: 0.10527284054919404\n",
      "Test mse: 0.10905866333095283\n",
      "Train mse: 0.10549358185794504\n",
      "Test mse: 0.10927602620250938\n",
      "Train mse: 0.10578703945624177\n",
      "Test mse: 0.10956847369440043\n",
      "Train mse: 0.10605207645378932\n",
      "Test mse: 0.10983259873656274\n",
      "Train mse: 0.10374828111363701\n",
      "Test mse: 0.10757603213713213\n",
      "Train mse: 0.10391969221839686\n",
      "Test mse: 0.10773874611309887\n",
      "Train mse: 0.10411372788376627\n",
      "Test mse: 0.10792573692370284\n",
      "Train mse: 0.10432499258866323\n",
      "Test mse: 0.10813139944944945\n",
      "Train mse: 0.10452957925145596\n",
      "Test mse: 0.10833119772328108\n",
      "Train mse: 0.10472108789997961\n",
      "Test mse: 0.10851850616623405\n",
      "Feature: 2, Split: 0.7876028972163656, Gain: 179.21427657983062, Left value: 0.6213051737969609, Right value: 4.196734617744879, Full intercept: 1.4210854715202004e-17, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 2, Split: 0.7796158068945256, Gain: 146.44585227537792, Left value: 0.5789523094061929, Right value: 3.5990969841571623, Full intercept: 0.007024637882099966, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 2, Split: 0.7739370499308397, Gain: 119.81887262728827, Left value: 0.534518518891313, Right value: 3.133551433841488, Full intercept: 0.01327068064443742, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 2, Split: 0.7658771677213638, Gain: 98.27731551379216, Left value: 0.4993592888533952, Right value: 2.695524365208796, Full intercept: 0.01885737272757811, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 2, Split: 0.7577964868717674, Gain: 80.79609887781021, Left value: 0.467199245111855, Right value: 2.32252595772811, Full intercept: 0.02385562241462114, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 2, Split: 0.7366593478293275, Gain: 66.7032505180325, Left value: 0.46649918903108134, Right value: 1.8805228200560897, Full intercept: 0.02834155444156906, Left intercept: 0.3053827948937096, Right intercept: None\n",
      "Feature: 1, Split: 0.6529823779519671, Gain: 59.23736728767509, Left value: 2.2341634082495663, Right value: 5.82254702243194, Full intercept: 0.03235896360876225, Left intercept: 0.40306207572022207, Right intercept: 0.7276883609726705\n",
      "Feature: 1, Split: 0.5858240373061092, Gain: 55.938617049279706, Left value: 3.2972578903213945, Right value: 7.4276570227896475, Full intercept: 0.04859772499332973, Left intercept: 0.40306207572022207, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.542898517566218, Gain: 58.644419413409615, Left value: 4.316349218321339, Right value: -0.6624794551961303, Full intercept: 0.0635838736666963, Left intercept: 0.40306207572022207, Right intercept: 0.614277512880183\n",
      "Feature: 1, Split: 0.49942350328393326, Gain: 86.91253081151329, Left value: 8.526534270281578, Right value: 0.15698957436324404, Full intercept: 0.09389409202375125, Left intercept: 0.42923878430092705, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.48159864763019, Gain: 119.153733093808, Left value: 10.407873682065182, Right value: -0.0585094565657128, Full intercept: 0.12046586802148253, Left intercept: 0.43014061825915223, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 154.8807834752653, Left value: 0.1685793502145391, Right value: -0.1369085346320618, Full intercept: 0.14489721039000727, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4749571334735014, Gain: 157.40920104495362, Left value: 0.18744310137544454, Right value: -0.11408529302544825, Full intercept: 0.1465568023116973, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4749571334735014, Gain: 159.85639979168445, Left value: 0.16869879123789994, Right value: -0.10267676372290335, Full intercept: 0.14812996517560756, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4749571334735014, Gain: 162.07504749332057, Left value: 0.1518289121141098, Right value: -0.09240908735061308, Full intercept: 0.14954581175312695, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4749571334735014, Gain: 164.0849271767514, Left value: 0.13664602090269917, Right value: -0.0831681786155517, Full intercept: 0.15082007367289438, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4749571334735014, Gain: 165.90495560001844, Left value: 0.12298141881242916, Right value: 0.7251520401954346, Full intercept: 0.15196690940068505, Left intercept: 0.3784676625605274, Right intercept: 0.6957586464725266\n",
      "Feature: 1, Split: 0.4713897047805968, Gain: 156.94678735259976, Left value: -0.05929758438827346, Right value: -0.18566360374486923, Full intercept: 0.1459019767310938, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47210135895697103, Gain: 158.4784717043524, Left value: -0.01928748923073036, Right value: -0.1592561909997584, Full intercept: 0.14703513629456397, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4721861949919668, Gain: 160.0015925320416, Left value: -0.013267531744851796, Right value: -0.1423918404741801, Full intercept: 0.1481227302174888, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4725133884701957, Gain: 161.39581616770158, Left value: 0.0042801592631923025, Right value: -0.12457651257332343, Full intercept: 0.14910999490045437, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47271548519580286, Gain: 162.72646294994354, Left value: 0.013855840997098875, Right value: -0.1098908492409398, Full intercept: 0.15003376131568275, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 163.9723854305187, Left value: 0.08101950681261536, Right value: -0.08267420802521085, Full intercept: 0.1508871528206916, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 165.3971750725602, Left value: 0.07291755613135331, Right value: -0.07440678722268973, Full intercept: 0.15180615619444615, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 166.68499743317633, Left value: 0.06562580051821827, Right value: 0.724244241015388, Full intercept: 0.15263325923082527, Left intercept: 0.3784676625605274, Right intercept: 0.6957586464725266\n",
      "Feature: 1, Split: 0.47109235950902395, Gain: 157.30441673488554, Left value: -0.08933143423047732, Right value: -0.1724890917020655, Full intercept: 0.1463113187509396, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4713897047805968, Gain: 158.50469911280442, Left value: -0.06598344270681777, Right value: -0.15193055650622456, Full intercept: 0.1472354358509995, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47210135895697103, Gain: 159.64870234891404, Left value: -0.025239742908133557, Right value: -0.12869778007590812, Full intercept: 0.148095095621424, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4721861949919668, Gain: 160.8189235240093, Left value: -0.018617702723257853, Right value: -0.11486789003822173, Full intercept: 0.14893629422546395, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.472344521596234, Gain: 161.89278362240177, Left value: -0.00890718310365126, Right value: -0.1016108328733641, Full intercept: 0.1497017767607188, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47271548519580286, Gain: 162.89615957790056, Left value: 0.010390430967848797, Right value: -0.08728386717662996, Full intercept: 0.15040756013930426, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47271548519580286, Gain: 163.8816591245481, Left value: 0.009351387871063885, Right value: -0.07855548045896692, Full intercept: 0.15108297034867793, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 164.77098072322485, Left value: 0.07704913965740724, Right value: -0.05409826427555522, Full intercept: 0.15169083953711426, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 165.87117150834666, Left value: 0.06934422569166662, Right value: -0.048688437847999734, Full intercept: 0.1523883826959114, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47414837582913155, Gain: 166.86472022586625, Left value: 0.062409803122500114, Right value: 0.7375547384897208, Full intercept: 0.15301617153882882, Left intercept: 0.3784676625605274, Right intercept: 0.6957586464725266\n",
      "Feature: 1, Split: 0.4708411667031412, Gain: 157.28551133065568, Left value: -0.10446181201719472, Right value: -0.15410127784915692, Full intercept: 0.14656034510137908, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4713897047805968, Gain: 158.1984431697472, Left value: -0.06753010379973487, Right value: -0.13246486040767316, Full intercept: 0.14729410360893527, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4719137945365742, Gain: 159.12711679841416, Left value: -0.03563648962688239, Right value: -0.11320777729696879, Full intercept: 0.14800489161332003, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.47210135895697103, Gain: 160.06597072442108, Left value: -0.023067415936195126, Right value: -0.09972499191545324, Full intercept: 0.14869381133618187, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Feature: 1, Split: 0.4721861949919668, Gain: 160.95009123804334, Left value: -0.01666586010474058, Right value: -0.08877216854076656, Full intercept: 0.14933192805288592, Left intercept: 0.3784676625605274, Right intercept: 0.6380503661347299\n",
      "Mean squared error: 0.10851850616623405\n"
     ]
    }
   ],
   "source": [
    "features = [f for f in dataset.columns if f not in [\"choice\"]]\n",
    "X, y = dataset[features].values, dataset[\"choice\"].values\n",
    "X_test, y_test = dataset_test[features].values, dataset_test[\"choice\"].values\n",
    "feature_indices = [(i * f_per_utility, (i + 1) * f_per_utility) for i in range(n_utility)]\n",
    "\n",
    "model = BoostingModel(n_estimators=40, learning_rate=0.1, num_classes=n_utility, linear_trees=True, from_split_point=True, feature_indices=feature_indices)\n",
    "\n",
    "model.fit(X, y, X_test=X_test, y_test=y_test)\n",
    "for ensemble in model.ensemble:\n",
    "    for tree in ensemble.trees:\n",
    "        feature, split, left_value, right_value, gain, left_constant, right_constant, left_intercept, right_intercept, full_intercept = tree.tree.values()\n",
    "        print(f\"Feature: {feature}, Split: {split}, Gain: {gain}, Left value: {left_value}, Right value: {right_value}, Full intercept: {full_intercept}, Left intercept: {left_intercept}, Right intercept: {right_intercept}\")\n",
    "\n",
    "if n_utility > 1:\n",
    "    preds = model.predict(X_test)\n",
    "    cel = cross_entropy(preds, y_test)\n",
    "    print(f\"Cross-entropy loss: {cel}\")\n",
    "else:\n",
    "    preds = model.predict(X_test, utilities=True)\n",
    "    mse = np.mean((preds - y_test.reshape(-1, 1))**2)\n",
    "    print(f\"Mean squared error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06e1d02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_plot = np.linspace(1e-4, 1, 1000)\n",
    "\n",
    "y_plot = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    plot_dataset = pd.DataFrame({feature_names[i]: np.zeros_like(x_plot) for i in range(f_per_utility*n_utility)})\n",
    "    plot_dataset[feature_names[i]] = x_plot\n",
    "\n",
    "    if n_utility == 2:\n",
    "        y_plot.append(model.predict(plot_dataset.values, utilities=True))\n",
    "    else:\n",
    "        y_plot.append(model.predict(plot_dataset.values, utilities=True)[:, i // f_per_utility])\n",
    "\n",
    "colours = [\"r\", \"g\", \"b\", \"y\", \"k\", \"magenta\", \"cyan\", \"orange\", \"purple\", \"brown\", \"pink\", \"grey\", \"olive\", \"lime\", \"teal\", \"coral\"]\n",
    "\n",
    "\n",
    "if n_utility == 2:\n",
    "    \n",
    "    y_plot_true = []\n",
    "    for i, (sp_i, beta_i, inter_i) in enumerate(zip(sp, betas, intercept)):\n",
    "        if i % f_per_utility == 0:\n",
    "            plt.figure()\n",
    "        y_plot_true.append(apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [0]).values)\n",
    "    \n",
    "    y_plot_ttrue = [y_1 - y_0 for y_0, y_1 in zip(y_plot_true[0], y_plot_true[1])]\n",
    "    y_plot_ttrue = np.array(y_plot_ttrue).reshape(-1)\n",
    "\n",
    "    plt.plot(x_plot, y_plot_ttrue, label=f\"{feature_names[0]}_true\", color=colours[0], linewidth=2)\n",
    "        # ascc = ascs[i//f_per_utility].cpu().numpy() if LPMC_model_fully_trained.device is not None else ascs[i//f_per_utility]\n",
    "        # plt.plot(x_plot, y_plot[i]+ascc, label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "    plt.plot(x_plot, y_plot[0], label=feature_names[0], color=colours[0], linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Utility 0\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "else:\n",
    "    for i, (sp_i, beta_i, inter_i) in enumerate(zip(sp, betas, intercept)):\n",
    "        if i % f_per_utility == 0:\n",
    "            plt.figure()\n",
    "        if i % f_per_utility == 0:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [0]).values\n",
    "        elif i % f_per_utility == 1:\n",
    "            y_plot_true = apply_constant_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 2:\n",
    "            y_plot_true = apply_sinusoidal_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 3:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        # y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        plt.plot(x_plot, y_plot_true, label=f\"{feature_names[i]}_true\", color=colours[i], linewidth=2)\n",
    "        # ascc = ascs[i//f_per_utility].cpu().numpy() if LPMC_model_fully_trained.device is not None else ascs[i//f_per_utility]\n",
    "        # plt.plot(x_plot, y_plot[i]+ascc, label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "        plt.plot(x_plot, y_plot[i], label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "        if i % f_per_utility == f_per_utility - 1:\n",
    "            plt.title(f\"Utility {i//f_per_utility}\")\n",
    "            plt.xlabel(\"x\")\n",
    "            plt.ylabel(\"y\")\n",
    "            plt.grid()\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.show()\n",
    "\n",
    "    # for i in range(len(feature_names)):\n",
    "    #     plt.figure()\n",
    "    #     plt.hist(dataset[feature_names[i]], bins=150, alpha=0.5, label=feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "276b6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "md = 1\n",
    "verbose = 2\n",
    "mono = False \n",
    "# monotonicity_0 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1] if mono else [0]*17\n",
    "monotonicity_0 = [1, 1, -1, 0] if mono else [0] * 17\n",
    "# monotonicity_0 = [1] if mono else [0] * 17\n",
    "l1 = 0\n",
    "l2 = 0\n",
    "min_data_in_leaf = 1\n",
    "min_sum_hessian_in_leaf = 0\n",
    "min_data_in_bin = 1\n",
    "mb = 250\n",
    "bf=1\n",
    "bfr=0\n",
    "variables_0 = feature_names[:f_per_utility]\n",
    "dico1 = []\n",
    "for i, v in enumerate(variables_0):\n",
    "    dico1.append({\n",
    "        \"utility\": [0],\n",
    "        \"variables\": [v],\n",
    "        \"boosting_params\": {\n",
    "            'boosting': 'gbdt',\n",
    "            'monotone_constraints_method': 'advanced',\n",
    "            \"objective\": \"regression\",\n",
    "            \"max_depth\": md,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": lr,\n",
    "            \"verbose\": verbose,\n",
    "            \"monotone_constraints\": [monotonicity_0[i]],\n",
    "            \"lambda_l2\": l2,\n",
    "            \"lambda_l1\": l1,\n",
    "            \"min_data_in_leaf\": min_data_in_leaf,\n",
    "            \"min_sum_hessian_in_leaf\": min_sum_hessian_in_leaf,\n",
    "            \"max_bin\": mb,\n",
    "            \"min_data_in_bin\": min_data_in_bin,\n",
    "            # \"num_classes\": 1,\n",
    "            \"bagging_fraction\": bf,\n",
    "            \"bagging_freq\": bfr,\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    })\n",
    "\n",
    "# monotonicity_1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1] if mono else [0]*17\n",
    "monotonicity_1 = [0, 1, -1, 1] if mono else [0]*17\n",
    "# monotonicity_1 = [1] if mono else [0]*17\n",
    "variables_1 = feature_names[f_per_utility:2*f_per_utility]\n",
    "dico2 = []\n",
    "for i, v in enumerate(variables_1):\n",
    "    dico2.append({\n",
    "        \"utility\": [1],\n",
    "        \"variables\": [v],\n",
    "        \"boosting_params\": {\n",
    "            'boosting': 'gbdt',\n",
    "            'monotone_constraints_method': 'advanced',\n",
    "            \"max_depth\": md,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": lr,\n",
    "            \"verbose\": verbose,\n",
    "            \"monotone_constraints\": [monotonicity_1[i]],\n",
    "            \"lambda_l2\": l2,\n",
    "            \"lambda_l1\": l1,\n",
    "            \"min_data_in_leaf\": min_data_in_leaf,\n",
    "            \"min_sum_hessian_in_leaf\": min_sum_hessian_in_leaf,\n",
    "            \"max_bin\": mb,\n",
    "            \"min_data_in_bin\": min_data_in_bin,\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    })\n",
    "    \n",
    "monotonicity_3 = [0 ,0, -1, 1] if mono else [0]*23\n",
    "# monotonicity_3 = [1] if mono else [0]*23\n",
    "# monotonicity_3 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1] if mono else [0]*23\n",
    "variables_3 = feature_names[2*f_per_utility:3*f_per_utility]\n",
    "dico3 = []\n",
    "for i, v in enumerate(variables_3):\n",
    "\n",
    "    dico3.append({\n",
    "        \"utility\": [2],\n",
    "        \"variables\": [v],\n",
    "        \"boosting_params\": {\n",
    "            'boosting': 'gbdt',\n",
    "            'monotone_constraints_method': 'advanced',\n",
    "            \"max_depth\": md,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": lr,\n",
    "            \"verbose\": verbose,\n",
    "            \"monotone_constraints\": [monotonicity_3[i]],\n",
    "            \"lambda_l2\": l2,\n",
    "            \"lambda_l1\": l1,\n",
    "            \"min_data_in_leaf\": min_data_in_leaf,\n",
    "            \"min_sum_hessian_in_leaf\": min_sum_hessian_in_leaf,\n",
    "            \"max_bin\": mb,\n",
    "            \"min_data_in_bin\": min_data_in_bin,\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    })\n",
    "\n",
    "monotonicity_4 = [0, 0, 0, -1] if mono else [0]*20\n",
    "# monotonicity_4 = [1] if mono else [0]*20\n",
    "variables_4 = feature_names[3*f_per_utility:]\n",
    "dico4 = []\n",
    "for i, v in enumerate(variables_4):\n",
    "    dico4.append({\n",
    "        \"utility\": [3],\n",
    "        \"variables\": [v],\n",
    "        \"boosting_params\": {\n",
    "            'boosting': 'gbdt',\n",
    "            'monotone_constraints_method': 'advanced',\n",
    "            \"max_depth\": md,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": lr,\n",
    "            \"verbose\": verbose,\n",
    "            \"monotone_constraints\": [monotonicity_4[i]],\n",
    "            \"lambda_l2\": l2,\n",
    "            \"lambda_l1\": l1,\n",
    "            \"min_data_in_leaf\": min_data_in_leaf,\n",
    "            \"min_sum_hessian_in_leaf\": min_sum_hessian_in_leaf,\n",
    "            \"max_bin\": mb,\n",
    "            \"min_data_in_bin\": min_data_in_bin,\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    })\n",
    "\n",
    "# rum_structure = dico1 + dico2 + dico3 #+ dico4\n",
    "if n_utility == 4:\n",
    "    rum_structure = dico1 + dico2 + dico3 + dico4\n",
    "elif n_utility == 3:\n",
    "    rum_structure = dico1 + dico2 + dico3\n",
    "else:\n",
    "    rum_structure = dico1\n",
    "# boost_from_param_space = [False] * len(rum_structure)\n",
    "boost_from_param_space = [True] * len(rum_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a9c08d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "general_params = {\n",
    "    \"n_jobs\": -1,\n",
    "    \"num_classes\": n_utility,  # important\n",
    "    \"verbosity\": 2,  # specific RUMBoost parameter\n",
    "    \"num_iterations\": 200,\n",
    "    # \"early_stopping_round\": 10,\n",
    "    # \"max_booster_to_update\": 23 * 4,\n",
    "    # \"max_booster_to_update\": 17 * 4,\n",
    "    # \"max_booster_to_update\": 8,\n",
    "    # \"max_booster_to_update\": n_utility * f_per_utility,\n",
    "    # \"max_booster_to_update\": 1,\n",
    "    \"max_booster_to_update\": n_utility,\n",
    "    # \"boost_from_parameter_space\": boost_from_param_space + boost_from_param_space2,\n",
    "    \"boost_from_parameter_space\": boost_from_param_space, #+ [False]*len(rum_structure2),\n",
    "    \"verbose_interval\": 1,\n",
    "    \"optim_interval\": 1,\n",
    "    \"objective\": \"regression\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f46eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensors = {\"device\":\"cuda\"}\n",
    "# torch_tensors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4bea3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specification = {\n",
    "    \"general_params\": general_params,\n",
    "    \"rum_structure\": rum_structure,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6bbc23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm\n",
    "from rumboost.rumboost import rum_train\n",
    "# features and label column names\n",
    "features = [f for f in dataset.columns if f != \"choice\"]\n",
    "label = \"choice\"\n",
    "\n",
    "# create lightgbm dataset\n",
    "lgb_train_set = lightgbm.Dataset(\n",
    "    dataset, label=dataset[label], free_raw_data=False\n",
    ")\n",
    "lgb_test_set = lightgbm.Dataset(\n",
    "    dataset_test, label=dataset_test[label], free_raw_data=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a15ab5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas-salvade/pwl-rumboost-experiment/src/rumboost/rumboost.py:2758: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch tensors on cuda\n",
      "[LightGBM] [Warning] Unknown parameter: max_booster_to_update\n",
      "[LightGBM] [Warning] Unknown parameter: boost_from_parameter_space\n",
      "[LightGBM] [Warning] Unknown parameter: verbose_interval\n",
      "[LightGBM] [Warning] Unknown parameter: optim_interval\n",
      "[LightGBM] [Warning] Unknown parameter: max_booster_to_update\n",
      "[LightGBM] [Warning] Unknown parameter: boost_from_parameter_space\n",
      "[LightGBM] [Warning] Unknown parameter: verbose_interval\n",
      "[LightGBM] [Warning] Unknown parameter: optim_interval\n",
      "[1]------NCE value on train set : 0.2395\n",
      "---------NCE value on test set 1: 1.3250\n",
      "[2]------NCE value on train set : 0.2245\n",
      "---------NCE value on test set 1: 1.3143\n",
      "[3]------NCE value on train set : 0.2142\n",
      "---------NCE value on test set 1: 1.3280\n",
      "[4]------NCE value on train set : 0.2026\n",
      "---------NCE value on test set 1: 1.3209\n",
      "[5]------NCE value on train set : 0.1949\n",
      "---------NCE value on test set 1: 1.3329\n",
      "[6]------NCE value on train set : 0.1860\n",
      "---------NCE value on test set 1: 1.3294\n",
      "[7]------NCE value on train set : 0.1802\n",
      "---------NCE value on test set 1: 1.3394\n",
      "[8]------NCE value on train set : 0.1733\n",
      "---------NCE value on test set 1: 1.3384\n",
      "[9]------NCE value on train set : 0.1690\n",
      "---------NCE value on test set 1: 1.3469\n",
      "[10]-----NCE value on train set : 0.1637\n",
      "---------NCE value on test set 1: 1.3478\n",
      "[11]-----NCE value on train set : 0.1605\n",
      "---------NCE value on test set 1: 1.3540\n",
      "[12]-----NCE value on train set : 0.1564\n",
      "---------NCE value on test set 1: 1.3572\n",
      "[13]-----NCE value on train set : 0.1539\n",
      "---------NCE value on test set 1: 1.3620\n",
      "[14]-----NCE value on train set : 0.1508\n",
      "---------NCE value on test set 1: 1.3661\n",
      "[15]-----NCE value on train set : 0.1490\n",
      "---------NCE value on test set 1: 1.3697\n",
      "[16]-----NCE value on train set : 0.1466\n",
      "---------NCE value on test set 1: 1.3745\n",
      "[17]-----NCE value on train set : 0.1452\n",
      "---------NCE value on test set 1: 1.3768\n",
      "[18]-----NCE value on train set : 0.1438\n",
      "---------NCE value on test set 1: 1.3665\n",
      "[19]-----NCE value on train set : 0.1419\n",
      "---------NCE value on test set 1: 1.3853\n",
      "[20]-----NCE value on train set : 0.1406\n",
      "---------NCE value on test set 1: 1.3709\n",
      "[21]-----NCE value on train set : 0.1394\n",
      "---------NCE value on test set 1: 1.3732\n",
      "[22]-----NCE value on train set : 0.1383\n",
      "---------NCE value on test set 1: 1.3743\n",
      "[23]-----NCE value on train set : 0.1372\n",
      "---------NCE value on test set 1: 1.3754\n",
      "[24]-----NCE value on train set : 0.1362\n",
      "---------NCE value on test set 1: 1.3765\n",
      "[25]-----NCE value on train set : 0.1348\n",
      "---------NCE value on test set 1: 1.3939\n",
      "[26]-----NCE value on train set : 0.1338\n",
      "---------NCE value on test set 1: 1.3805\n",
      "[27]-----NCE value on train set : 0.1329\n",
      "---------NCE value on test set 1: 1.3941\n",
      "[28]-----NCE value on train set : 0.1320\n",
      "---------NCE value on test set 1: 1.3839\n",
      "[29]-----NCE value on train set : 0.1312\n",
      "---------NCE value on test set 1: 1.3855\n",
      "[30]-----NCE value on train set : 0.1304\n",
      "---------NCE value on test set 1: 1.3863\n",
      "[31]-----NCE value on train set : 0.1296\n",
      "---------NCE value on test set 1: 1.3871\n",
      "[32]-----NCE value on train set : 0.1289\n",
      "---------NCE value on test set 1: 1.3979\n",
      "[33]-----NCE value on train set : 0.1282\n",
      "---------NCE value on test set 1: 1.3893\n",
      "[34]-----NCE value on train set : 0.1271\n",
      "---------NCE value on test set 1: 1.4056\n",
      "[35]-----NCE value on train set : 0.1264\n",
      "---------NCE value on test set 1: 1.3934\n",
      "[36]-----NCE value on train set : 0.1257\n",
      "---------NCE value on test set 1: 1.3976\n",
      "[37]-----NCE value on train set : 0.1251\n",
      "---------NCE value on test set 1: 1.3942\n",
      "[38]-----NCE value on train set : 0.1244\n",
      "---------NCE value on test set 1: 1.3965\n",
      "[39]-----NCE value on train set : 0.1238\n",
      "---------NCE value on test set 1: 1.3948\n",
      "[40]-----NCE value on train set : 0.1232\n",
      "---------NCE value on test set 1: 1.3957\n",
      "[41]-----NCE value on train set : 0.1226\n",
      "---------NCE value on test set 1: 1.4051\n",
      "[42]-----NCE value on train set : 0.1221\n",
      "---------NCE value on test set 1: 1.3991\n",
      "[43]-----NCE value on train set : 0.1215\n",
      "---------NCE value on test set 1: 1.3981\n",
      "[44]-----NCE value on train set : 0.1206\n",
      "---------NCE value on test set 1: 1.4120\n",
      "[45]-----NCE value on train set : 0.1201\n",
      "---------NCE value on test set 1: 1.4015\n",
      "[46]-----NCE value on train set : 0.1195\n",
      "---------NCE value on test set 1: 1.4041\n",
      "[47]-----NCE value on train set : 0.1190\n",
      "---------NCE value on test set 1: 1.4025\n",
      "[48]-----NCE value on train set : 0.1185\n",
      "---------NCE value on test set 1: 1.4043\n",
      "[49]-----NCE value on train set : 0.1180\n",
      "---------NCE value on test set 1: 1.4031\n",
      "[50]-----NCE value on train set : 0.1173\n",
      "---------NCE value on test set 1: 1.4159\n",
      "[51]-----NCE value on train set : 0.1168\n",
      "---------NCE value on test set 1: 1.4064\n",
      "[52]-----NCE value on train set : 0.1163\n",
      "---------NCE value on test set 1: 1.4084\n",
      "[53]-----NCE value on train set : 0.1159\n",
      "---------NCE value on test set 1: 1.4075\n",
      "[54]-----NCE value on train set : 0.1155\n",
      "---------NCE value on test set 1: 1.4158\n",
      "[55]-----NCE value on train set : 0.1150\n",
      "---------NCE value on test set 1: 1.4095\n",
      "[56]-----NCE value on train set : 0.1146\n",
      "---------NCE value on test set 1: 1.4111\n",
      "[57]-----NCE value on train set : 0.1142\n",
      "---------NCE value on test set 1: 1.4104\n",
      "[58]-----NCE value on train set : 0.1136\n",
      "---------NCE value on test set 1: 1.4220\n",
      "[59]-----NCE value on train set : 0.1132\n",
      "---------NCE value on test set 1: 1.4142\n",
      "[60]-----NCE value on train set : 0.1128\n",
      "---------NCE value on test set 1: 1.4140\n",
      "[61]-----NCE value on train set : 0.1124\n",
      "---------NCE value on test set 1: 1.4152\n",
      "[62]-----NCE value on train set : 0.1121\n",
      "---------NCE value on test set 1: 1.4144\n",
      "[63]-----NCE value on train set : 0.1117\n",
      "---------NCE value on test set 1: 1.4211\n",
      "[64]-----NCE value on train set : 0.1114\n",
      "---------NCE value on test set 1: 1.4164\n",
      "[65]-----NCE value on train set : 0.1110\n",
      "---------NCE value on test set 1: 1.4180\n",
      "[66]-----NCE value on train set : 0.1107\n",
      "---------NCE value on test set 1: 1.4172\n",
      "[67]-----NCE value on train set : 0.1102\n",
      "---------NCE value on test set 1: 1.4276\n",
      "[68]-----NCE value on train set : 0.1098\n",
      "---------NCE value on test set 1: 1.4202\n",
      "[69]-----NCE value on train set : 0.1095\n",
      "---------NCE value on test set 1: 1.4217\n",
      "[70]-----NCE value on train set : 0.1092\n",
      "---------NCE value on test set 1: 1.4211\n",
      "[71]-----NCE value on train set : 0.1089\n",
      "---------NCE value on test set 1: 1.4219\n",
      "[72]-----NCE value on train set : 0.1087\n",
      "---------NCE value on test set 1: 1.4217\n",
      "[73]-----NCE value on train set : 0.1084\n",
      "---------NCE value on test set 1: 1.4286\n",
      "[74]-----NCE value on train set : 0.1081\n",
      "---------NCE value on test set 1: 1.4233\n",
      "[75]-----NCE value on train set : 0.1079\n",
      "---------NCE value on test set 1: 1.4244\n",
      "[76]-----NCE value on train set : 0.1074\n",
      "---------NCE value on test set 1: 1.4330\n",
      "[77]-----NCE value on train set : 0.1071\n",
      "---------NCE value on test set 1: 1.4265\n",
      "[78]-----NCE value on train set : 0.1069\n",
      "---------NCE value on test set 1: 1.4277\n",
      "[79]-----NCE value on train set : 0.1066\n",
      "---------NCE value on test set 1: 1.4274\n",
      "[80]-----NCE value on train set : 0.1064\n",
      "---------NCE value on test set 1: 1.4282\n",
      "[81]-----NCE value on train set : 0.1062\n",
      "---------NCE value on test set 1: 1.4279\n",
      "[82]-----NCE value on train set : 0.1059\n",
      "---------NCE value on test set 1: 1.4314\n",
      "[83]-----NCE value on train set : 0.1057\n",
      "---------NCE value on test set 1: 1.4296\n",
      "[84]-----NCE value on train set : 0.1053\n",
      "---------NCE value on test set 1: 1.4382\n",
      "[85]-----NCE value on train set : 0.1051\n",
      "---------NCE value on test set 1: 1.4327\n",
      "[86]-----NCE value on train set : 0.1049\n",
      "---------NCE value on test set 1: 1.4328\n",
      "[87]-----NCE value on train set : 0.1047\n",
      "---------NCE value on test set 1: 1.4335\n",
      "[88]-----NCE value on train set : 0.1045\n",
      "---------NCE value on test set 1: 1.4332\n",
      "[89]-----NCE value on train set : 0.1043\n",
      "---------NCE value on test set 1: 1.4337\n",
      "[90]-----NCE value on train set : 0.1041\n",
      "---------NCE value on test set 1: 1.4365\n",
      "[91]-----NCE value on train set : 0.1039\n",
      "---------NCE value on test set 1: 1.4354\n",
      "[92]-----NCE value on train set : 0.1037\n",
      "---------NCE value on test set 1: 1.4353\n",
      "[93]-----NCE value on train set : 0.1034\n",
      "---------NCE value on test set 1: 1.4428\n",
      "[94]-----NCE value on train set : 0.1032\n",
      "---------NCE value on test set 1: 1.4379\n",
      "[95]-----NCE value on train set : 0.1030\n",
      "---------NCE value on test set 1: 1.4382\n",
      "[96]-----NCE value on train set : 0.1029\n",
      "---------NCE value on test set 1: 1.4386\n",
      "[97]-----NCE value on train set : 0.1025\n",
      "---------NCE value on test set 1: 1.4470\n",
      "[98]-----NCE value on train set : 0.1024\n",
      "---------NCE value on test set 1: 1.4400\n",
      "[99]-----NCE value on train set : 0.1022\n",
      "---------NCE value on test set 1: 1.4405\n",
      "[100]----NCE value on train set : 0.1020\n",
      "---------NCE value on test set 1: 1.4409\n",
      "[101]----NCE value on train set : 0.1019\n",
      "---------NCE value on test set 1: 1.4409\n",
      "[102]----NCE value on train set : 0.1017\n",
      "---------NCE value on test set 1: 1.4413\n",
      "[103]----NCE value on train set : 0.1016\n",
      "---------NCE value on test set 1: 1.4414\n",
      "[104]----NCE value on train set : 0.1013\n",
      "---------NCE value on test set 1: 1.4481\n",
      "[105]----NCE value on train set : 0.1012\n",
      "---------NCE value on test set 1: 1.4437\n",
      "[106]----NCE value on train set : 0.1010\n",
      "---------NCE value on test set 1: 1.4441\n",
      "[107]----NCE value on train set : 0.1009\n",
      "---------NCE value on test set 1: 1.4486\n",
      "[108]----NCE value on train set : 0.1008\n",
      "---------NCE value on test set 1: 1.4451\n",
      "[109]----NCE value on train set : 0.1005\n",
      "---------NCE value on test set 1: 1.4529\n",
      "[110]----NCE value on train set : 0.1004\n",
      "---------NCE value on test set 1: 1.4467\n",
      "[111]----NCE value on train set : 0.1003\n",
      "---------NCE value on test set 1: 1.4471\n",
      "[112]----NCE value on train set : 0.1001\n",
      "---------NCE value on test set 1: 1.4475\n",
      "[113]----NCE value on train set : 0.1000\n",
      "---------NCE value on test set 1: 1.4474\n",
      "[114]----NCE value on train set : 0.0999\n",
      "---------NCE value on test set 1: 1.4478\n",
      "[115]----NCE value on train set : 0.0997\n",
      "---------NCE value on test set 1: 1.4549\n",
      "[116]----NCE value on train set : 0.0996\n",
      "---------NCE value on test set 1: 1.4488\n",
      "[117]----NCE value on train set : 0.0994\n",
      "---------NCE value on test set 1: 1.4496\n",
      "[118]----NCE value on train set : 0.0993\n",
      "---------NCE value on test set 1: 1.4495\n",
      "[119]----NCE value on train set : 0.0991\n",
      "---------NCE value on test set 1: 1.4554\n",
      "[120]----NCE value on train set : 0.0990\n",
      "---------NCE value on test set 1: 1.4516\n",
      "[121]----NCE value on train set : 0.0989\n",
      "---------NCE value on test set 1: 1.4518\n",
      "[122]----NCE value on train set : 0.0988\n",
      "---------NCE value on test set 1: 1.4520\n",
      "[123]----NCE value on train set : 0.0987\n",
      "---------NCE value on test set 1: 1.4537\n",
      "[124]----NCE value on train set : 0.0986\n",
      "---------NCE value on test set 1: 1.4531\n",
      "[125]----NCE value on train set : 0.0985\n",
      "---------NCE value on test set 1: 1.4531\n",
      "[126]----NCE value on train set : 0.0983\n",
      "---------NCE value on test set 1: 1.4597\n",
      "[127]----NCE value on train set : 0.0983\n",
      "---------NCE value on test set 1: 1.4544\n",
      "[128]----NCE value on train set : 0.0982\n",
      "---------NCE value on test set 1: 1.4547\n",
      "[129]----NCE value on train set : 0.0981\n",
      "---------NCE value on test set 1: 1.4549\n",
      "[130]----NCE value on train set : 0.0979\n",
      "---------NCE value on test set 1: 1.4601\n",
      "[131]----NCE value on train set : 0.0978\n",
      "---------NCE value on test set 1: 1.4567\n",
      "[132]----NCE value on train set : 0.0977\n",
      "---------NCE value on test set 1: 1.4569\n",
      "[133]----NCE value on train set : 0.0977\n",
      "---------NCE value on test set 1: 1.4570\n",
      "[134]----NCE value on train set : 0.0976\n",
      "---------NCE value on test set 1: 1.4585\n",
      "[135]----NCE value on train set : 0.0975\n",
      "---------NCE value on test set 1: 1.4579\n",
      "[136]----NCE value on train set : 0.0974\n",
      "---------NCE value on test set 1: 1.4581\n",
      "[137]----NCE value on train set : 0.0973\n",
      "---------NCE value on test set 1: 1.4640\n",
      "[138]----NCE value on train set : 0.0972\n",
      "---------NCE value on test set 1: 1.4592\n",
      "[139]----NCE value on train set : 0.0971\n",
      "---------NCE value on test set 1: 1.4635\n",
      "[140]----NCE value on train set : 0.0971\n",
      "---------NCE value on test set 1: 1.4587\n",
      "[141]----NCE value on train set : 0.0969\n",
      "---------NCE value on test set 1: 1.4639\n",
      "[142]----NCE value on train set : 0.0968\n",
      "---------NCE value on test set 1: 1.4608\n",
      "[143]----NCE value on train set : 0.0968\n",
      "---------NCE value on test set 1: 1.4609\n",
      "[144]----NCE value on train set : 0.0967\n",
      "---------NCE value on test set 1: 1.4665\n",
      "[145]----NCE value on train set : 0.0966\n",
      "---------NCE value on test set 1: 1.4607\n",
      "[146]----NCE value on train set : 0.0966\n",
      "---------NCE value on test set 1: 1.4653\n",
      "[147]----NCE value on train set : 0.0965\n",
      "---------NCE value on test set 1: 1.4604\n",
      "[148]----NCE value on train set : 0.0964\n",
      "---------NCE value on test set 1: 1.4662\n",
      "[149]----NCE value on train set : 0.0964\n",
      "---------NCE value on test set 1: 1.4606\n",
      "[150]----NCE value on train set : 0.0963\n",
      "---------NCE value on test set 1: 1.4641\n",
      "[151]----NCE value on train set : 0.0962\n",
      "---------NCE value on test set 1: 1.4618\n",
      "[152]----NCE value on train set : 0.0962\n",
      "---------NCE value on test set 1: 1.4621\n",
      "[153]----NCE value on train set : 0.0961\n",
      "---------NCE value on test set 1: 1.4673\n",
      "[154]----NCE value on train set : 0.0961\n",
      "---------NCE value on test set 1: 1.4619\n",
      "[155]----NCE value on train set : 0.0960\n",
      "---------NCE value on test set 1: 1.4665\n",
      "[156]----NCE value on train set : 0.0959\n",
      "---------NCE value on test set 1: 1.4617\n",
      "[157]----NCE value on train set : 0.0959\n",
      "---------NCE value on test set 1: 1.4672\n",
      "[158]----NCE value on train set : 0.0958\n",
      "---------NCE value on test set 1: 1.4619\n",
      "[159]----NCE value on train set : 0.0957\n",
      "---------NCE value on test set 1: 1.4667\n",
      "[160]----NCE value on train set : 0.0956\n",
      "---------NCE value on test set 1: 1.4638\n",
      "[161]----NCE value on train set : 0.0956\n",
      "---------NCE value on test set 1: 1.4680\n",
      "[162]----NCE value on train set : 0.0955\n",
      "---------NCE value on test set 1: 1.4634\n",
      "[163]----NCE value on train set : 0.0954\n",
      "---------NCE value on test set 1: 1.4689\n",
      "[164]----NCE value on train set : 0.0954\n",
      "---------NCE value on test set 1: 1.4636\n",
      "[165]----NCE value on train set : 0.0953\n",
      "---------NCE value on test set 1: 1.4693\n",
      "[166]----NCE value on train set : 0.0952\n",
      "---------NCE value on test set 1: 1.4650\n",
      "[167]----NCE value on train set : 0.0951\n",
      "---------NCE value on test set 1: 1.4654\n",
      "[168]----NCE value on train set : 0.0951\n",
      "---------NCE value on test set 1: 1.4704\n",
      "[169]----NCE value on train set : 0.0950\n",
      "---------NCE value on test set 1: 1.4651\n",
      "[170]----NCE value on train set : 0.0950\n",
      "---------NCE value on test set 1: 1.4694\n",
      "[171]----NCE value on train set : 0.0949\n",
      "---------NCE value on test set 1: 1.4649\n",
      "[172]----NCE value on train set : 0.0949\n",
      "---------NCE value on test set 1: 1.4702\n",
      "[173]----NCE value on train set : 0.0948\n",
      "---------NCE value on test set 1: 1.4651\n",
      "[174]----NCE value on train set : 0.0948\n",
      "---------NCE value on test set 1: 1.4667\n",
      "[175]----NCE value on train set : 0.0947\n",
      "---------NCE value on test set 1: 1.4663\n",
      "[176]----NCE value on train set : 0.0946\n",
      "---------NCE value on test set 1: 1.4664\n",
      "[177]----NCE value on train set : 0.0946\n",
      "---------NCE value on test set 1: 1.4712\n",
      "[178]----NCE value on train set : 0.0945\n",
      "---------NCE value on test set 1: 1.4662\n",
      "[179]----NCE value on train set : 0.0945\n",
      "---------NCE value on test set 1: 1.4705\n",
      "[180]----NCE value on train set : 0.0944\n",
      "---------NCE value on test set 1: 1.4661\n",
      "[181]----NCE value on train set : 0.0944\n",
      "---------NCE value on test set 1: 1.4712\n",
      "[182]----NCE value on train set : 0.0943\n",
      "---------NCE value on test set 1: 1.4663\n",
      "[183]----NCE value on train set : 0.0942\n",
      "---------NCE value on test set 1: 1.4718\n",
      "[184]----NCE value on train set : 0.0942\n",
      "---------NCE value on test set 1: 1.4676\n",
      "[185]----NCE value on train set : 0.0941\n",
      "---------NCE value on test set 1: 1.4716\n",
      "[186]----NCE value on train set : 0.0941\n",
      "---------NCE value on test set 1: 1.4673\n",
      "[187]----NCE value on train set : 0.0940\n",
      "---------NCE value on test set 1: 1.4723\n",
      "[188]----NCE value on train set : 0.0940\n",
      "---------NCE value on test set 1: 1.4675\n",
      "[189]----NCE value on train set : 0.0939\n",
      "---------NCE value on test set 1: 1.4719\n",
      "[190]----NCE value on train set : 0.0938\n",
      "---------NCE value on test set 1: 1.4693\n",
      "[191]----NCE value on train set : 0.0938\n",
      "---------NCE value on test set 1: 1.4730\n",
      "[192]----NCE value on train set : 0.0937\n",
      "---------NCE value on test set 1: 1.4688\n",
      "[193]----NCE value on train set : 0.0937\n",
      "---------NCE value on test set 1: 1.4738\n",
      "[194]----NCE value on train set : 0.0936\n",
      "---------NCE value on test set 1: 1.4689\n",
      "[195]----NCE value on train set : 0.0936\n",
      "---------NCE value on test set 1: 1.4695\n",
      "[196]----NCE value on train set : 0.0935\n",
      "---------NCE value on test set 1: 1.4740\n",
      "[197]----NCE value on train set : 0.0935\n",
      "---------NCE value on test set 1: 1.4694\n",
      "[198]----NCE value on train set : 0.0934\n",
      "---------NCE value on test set 1: 1.4734\n",
      "[199]----NCE value on train set : 0.0934\n",
      "---------NCE value on test set 1: 1.4692\n",
      "[200]----NCE value on train set : 0.0934\n",
      "---------NCE value on test set 1: 1.4740\n"
     ]
    }
   ],
   "source": [
    "LPMC_model_fully_trained = rum_train(lgb_train_set, model_specification, valid_sets=[lgb_test_set], torch_tensors=torch_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45cc4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_plot = np.linspace(1e-4, 1, 1000)\n",
    "\n",
    "y_plot = []\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    plot_dataset = pd.DataFrame({feature_names[i]: np.zeros_like(x_plot) for i in range(f_per_utility*n_utility)})\n",
    "    plot_dataset[feature_names[i]] = x_plot\n",
    "    plot_dataset_lgb = lightgbm.Dataset(plot_dataset, free_raw_data=False)\n",
    "\n",
    "    if n_utility == 2:\n",
    "        y_plot.append(LPMC_model_fully_trained.predict(plot_dataset_lgb, utilities=True))\n",
    "    else:\n",
    "        y_plot.append(LPMC_model_fully_trained.predict(plot_dataset_lgb, utilities=True)[:, i // f_per_utility])\n",
    "    if LPMC_model_fully_trained.device is not None:\n",
    "        y_plot[-1] = y_plot[-1].cpu().numpy()\n",
    "\n",
    "colours = [\"r\", \"g\", \"b\", \"y\", \"k\", \"magenta\", \"cyan\", \"orange\", \"purple\", \"brown\", \"pink\", \"grey\", \"olive\", \"lime\", \"teal\", \"coral\"]\n",
    "\n",
    "\n",
    "if n_utility == 2:\n",
    "    \n",
    "    y_plot_true = []\n",
    "    for i, (sp_i, beta_i, inter_i) in enumerate(zip(sp, betas, intercept)):\n",
    "        if i % f_per_utility == 0:\n",
    "            plt.figure()\n",
    "        if i % f_per_utility == 0:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [0]).values\n",
    "        elif i % f_per_utility == 1:\n",
    "            y_plot_true = apply_constant_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 2:\n",
    "            y_plot_true = apply_sinusoidal_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 3:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "    \n",
    "    y_plot_ttrue = [y_1 - y_0 for y_0, y_1 in zip(y_plot_true[0], y_plot_true[1])]\n",
    "    y_plot_ttrue = np.array(y_plot_ttrue).reshape(-1)\n",
    "\n",
    "    plt.plot(x_plot, y_plot_ttrue, label=f\"{feature_names[0]}_true\", color=colours[0], linewidth=2)\n",
    "        # ascc = ascs[i//f_per_utility].cpu().numpy() if LPMC_model_fully_trained.device is not None else ascs[i//f_per_utility]\n",
    "        # plt.plot(x_plot, y_plot[i]+ascc, label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "    plt.plot(x_plot, y_plot[0], label=feature_names[0], color=colours[0], linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    plt.title(f\"Utility 0\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.show()\n",
    "else:\n",
    "    for i, (sp_i, beta_i, inter_i) in enumerate(zip(sp, betas, intercept)):\n",
    "        if i % f_per_utility == 0:\n",
    "            plt.figure()\n",
    "        if i % f_per_utility == 0:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [0]).values\n",
    "        elif i % f_per_utility == 1:\n",
    "            y_plot_true = apply_constant_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 2:\n",
    "            y_plot_true = apply_sinusoidal_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        elif i % f_per_utility == 3:\n",
    "            y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        # y_plot_true = apply_linear_feature(x_plot.reshape(-1,1), sp_i.reshape(1,-1), beta_i.reshape(1,-1), feature_names[i], [inter_i]).values\n",
    "        plt.plot(x_plot, y_plot_true, label=f\"{feature_names[i]}_true\", color=colours[i], linewidth=2)\n",
    "        # ascc = ascs[i//f_per_utility].cpu().numpy() if LPMC_model_fully_trained.device is not None else ascs[i//f_per_utility]\n",
    "        # plt.plot(x_plot, y_plot[i]+ascc, label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "        plt.plot(x_plot, y_plot[i], label=feature_names[i], color=colours[i], linestyle=\"--\", linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "        if i % f_per_utility == f_per_utility - 1:\n",
    "            plt.title(f\"Utility {i//f_per_utility}\")\n",
    "            plt.xlabel(\"x\")\n",
    "            plt.ylabel(\"y\")\n",
    "            plt.grid()\n",
    "            plt.legend(fontsize=12)\n",
    "            plt.show()\n",
    "\n",
    "    # for i in range(len(feature_names)):\n",
    "    #     plt.figure()\n",
    "    #     plt.hist(dataset[feature_names[i]], bins=150, alpha=0.5, label=feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b6efdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tree_index  node_depth node_index left_child right_child parent_index  \\\n",
      "0            0           1       0-S0       0-L0        0-L1         None   \n",
      "1            0           2       0-L0       None        None         0-S0   \n",
      "2            0           2       0-L1       None        None         0-S0   \n",
      "3            1           1       1-S0       1-L0        1-L1         None   \n",
      "4            1           2       1-L0       None        None         1-S0   \n",
      "5            1           2       1-L1       None        None         1-S0   \n",
      "6            2           1       2-S0       2-L0        2-L1         None   \n",
      "7            2           2       2-L0       None        None         2-S0   \n",
      "8            2           2       2-L1       None        None         2-S0   \n",
      "9            3           1       3-S0       3-L0        3-L1         None   \n",
      "10           3           2       3-L0       None        None         3-S0   \n",
      "11           3           2       3-L1       None        None         3-S0   \n",
      "12           4           1       4-S0       4-L0        4-L1         None   \n",
      "13           4           2       4-L0       None        None         4-S0   \n",
      "14           4           2       4-L1       None        None         4-S0   \n",
      "15           5           1       5-S0       5-L0        5-L1         None   \n",
      "16           5           2       5-L0       None        None         5-S0   \n",
      "17           5           2       5-L1       None        None         5-S0   \n",
      "18           6           1       6-S0       6-L0        6-L1         None   \n",
      "19           6           2       6-L0       None        None         6-S0   \n",
      "20           6           2       6-L1       None        None         6-S0   \n",
      "21           7           1       7-S0       7-L0        7-L1         None   \n",
      "22           7           2       7-L0       None        None         7-S0   \n",
      "23           7           2       7-L1       None        None         7-S0   \n",
      "24           8           1       8-S0       8-L0        8-L1         None   \n",
      "25           8           2       8-L0       None        None         8-S0   \n",
      "26           8           2       8-L1       None        None         8-S0   \n",
      "27           9           1       9-S0       9-L0        9-L1         None   \n",
      "28           9           2       9-L0       None        None         9-S0   \n",
      "29           9           2       9-L1       None        None         9-S0   \n",
      "\n",
      "   split_feature  split_gain  threshold decision_type missing_direction  \\\n",
      "0             f0   45.012699   0.332292            <=              left   \n",
      "1           None         NaN        NaN          None              None   \n",
      "2           None         NaN        NaN          None              None   \n",
      "3             f0   49.229900   0.332292            <=              left   \n",
      "4           None         NaN        NaN          None              None   \n",
      "5           None         NaN        NaN          None              None   \n",
      "6             f0   45.011002   0.332292            <=              left   \n",
      "7           None         NaN        NaN          None              None   \n",
      "8           None         NaN        NaN          None              None   \n",
      "9             f0   41.677399   0.332292            <=              left   \n",
      "10          None         NaN        NaN          None              None   \n",
      "11          None         NaN        NaN          None              None   \n",
      "12            f0   38.933998   0.332292            <=              left   \n",
      "13          None         NaN        NaN          None              None   \n",
      "14          None         NaN        NaN          None              None   \n",
      "15            f0   36.237598   0.332292            <=              left   \n",
      "16          None         NaN        NaN          None              None   \n",
      "17          None         NaN        NaN          None              None   \n",
      "18            f0   33.790798   0.347724            <=              left   \n",
      "19          None         NaN        NaN          None              None   \n",
      "20          None         NaN        NaN          None              None   \n",
      "21            f0   31.440300   0.347724            <=              left   \n",
      "22          None         NaN        NaN          None              None   \n",
      "23          None         NaN        NaN          None              None   \n",
      "24            f0   28.652399   0.347724            <=              left   \n",
      "25          None         NaN        NaN          None              None   \n",
      "26          None         NaN        NaN          None              None   \n",
      "27            f0   27.388000   0.347724            <=              left   \n",
      "28          None         NaN        NaN          None              None   \n",
      "29          None         NaN        NaN          None              None   \n",
      "\n",
      "   missing_type     value      weight  count  \n",
      "0          None  0.000000    0.000000   2000  \n",
      "1          None  0.213277    7.191735    648  \n",
      "2          None  0.041346  200.657889   1352  \n",
      "3          None  0.000000    0.000000   2000  \n",
      "4          None  0.235511    7.499696    648  \n",
      "5          None  0.025182  212.385598   1352  \n",
      "6          None  0.000000    0.000000   2000  \n",
      "7          None  0.226100    7.421243    648  \n",
      "8          None  0.024428  213.004878   1352  \n",
      "9          None  0.000000    0.000000   2000  \n",
      "10         None  0.219045    7.366171    648  \n",
      "11         None  0.022875  214.161018   1352  \n",
      "12         None  0.000000    0.000000   2000  \n",
      "13         None  0.213458    7.324920    648  \n",
      "14         None  0.020976  215.527910   1352  \n",
      "15         None  0.000000    0.000000   2000  \n",
      "16         None  0.207353    7.274101    648  \n",
      "17         None  0.019562  216.542621   1352  \n",
      "18         None  0.000000    0.000000   2000  \n",
      "19         None  0.185717    8.382094    678  \n",
      "20         None  0.018918  216.247488   1322  \n",
      "21         None  0.000000    0.000000   2000  \n",
      "22         None  0.180111    8.320399    678  \n",
      "23         None  0.017971  216.918239   1322  \n",
      "24         None  0.000000    0.000000   2000  \n",
      "25         None  0.172632    8.228111    678  \n",
      "26         None  0.017476  217.291163   1322  \n",
      "27         None  0.000000    0.000000   2000  \n",
      "28         None  0.172227    8.242402    678  \n",
      "29         None  0.013444  219.903729   1322  \n",
      "    tree_index  node_depth node_index left_child right_child parent_index  \\\n",
      "0            0           1       0-S0       0-L0        0-L1         None   \n",
      "1            0           2       0-L0       None        None         0-S0   \n",
      "2            0           2       0-L1       None        None         0-S0   \n",
      "3            1           1       1-S0       1-L0        1-L1         None   \n",
      "4            1           2       1-L0       None        None         1-S0   \n",
      "5            1           2       1-L1       None        None         1-S0   \n",
      "6            2           1       2-S0       2-L0        2-L1         None   \n",
      "7            2           2       2-L0       None        None         2-S0   \n",
      "8            2           2       2-L1       None        None         2-S0   \n",
      "9            3           1       3-S0       3-L0        3-L1         None   \n",
      "10           3           2       3-L0       None        None         3-S0   \n",
      "11           3           2       3-L1       None        None         3-S0   \n",
      "12           4           1       4-S0       4-L0        4-L1         None   \n",
      "13           4           2       4-L0       None        None         4-S0   \n",
      "14           4           2       4-L1       None        None         4-S0   \n",
      "15           5           1       5-S0       5-L0        5-L1         None   \n",
      "16           5           2       5-L0       None        None         5-S0   \n",
      "17           5           2       5-L1       None        None         5-S0   \n",
      "18           6           1       6-S0       6-L0        6-L1         None   \n",
      "19           6           2       6-L0       None        None         6-S0   \n",
      "20           6           2       6-L1       None        None         6-S0   \n",
      "21           7           1       7-S0       7-L0        7-L1         None   \n",
      "22           7           2       7-L0       None        None         7-S0   \n",
      "23           7           2       7-L1       None        None         7-S0   \n",
      "24           8           1       8-S0       8-L0        8-L1         None   \n",
      "25           8           2       8-L0       None        None         8-S0   \n",
      "26           8           2       8-L1       None        None         8-S0   \n",
      "27           9           1       9-S0       9-L0        9-L1         None   \n",
      "28           9           2       9-L0       None        None         9-S0   \n",
      "29           9           2       9-L1       None        None         9-S0   \n",
      "\n",
      "   split_feature  split_gain  threshold decision_type missing_direction  \\\n",
      "0             f1     6.67474   0.103098            <=              left   \n",
      "1           None         NaN        NaN          None              None   \n",
      "2           None         NaN        NaN          None              None   \n",
      "3             f1     8.01977   0.103098            <=              left   \n",
      "4           None         NaN        NaN          None              None   \n",
      "5           None         NaN        NaN          None              None   \n",
      "6             f1     6.90074   0.103098            <=              left   \n",
      "7           None         NaN        NaN          None              None   \n",
      "8           None         NaN        NaN          None              None   \n",
      "9             f1     6.42010   0.145076            <=              left   \n",
      "10          None         NaN        NaN          None              None   \n",
      "11          None         NaN        NaN          None              None   \n",
      "12            f1     5.87108   0.174438            <=              left   \n",
      "13          None         NaN        NaN          None              None   \n",
      "14          None         NaN        NaN          None              None   \n",
      "15            f1     5.32345   0.174438            <=              left   \n",
      "16          None         NaN        NaN          None              None   \n",
      "17          None         NaN        NaN          None              None   \n",
      "18            f1     4.95984   0.174438            <=              left   \n",
      "19          None         NaN        NaN          None              None   \n",
      "20          None         NaN        NaN          None              None   \n",
      "21            f1     4.63552   0.174438            <=              left   \n",
      "22          None         NaN        NaN          None              None   \n",
      "23          None         NaN        NaN          None              None   \n",
      "24            f1     4.03253   0.945707            <=              left   \n",
      "25          None         NaN        NaN          None              None   \n",
      "26          None         NaN        NaN          None              None   \n",
      "27            f1     4.68200   0.945707            <=              left   \n",
      "28          None         NaN        NaN          None              None   \n",
      "29          None         NaN        NaN          None              None   \n",
      "\n",
      "   missing_type     value      weight  count  \n",
      "0          None  0.000000    0.000000   2000  \n",
      "1          None  0.529369    0.235197    211  \n",
      "2          None  0.003642  217.375311   1789  \n",
      "3          None  0.000000    0.000000   2000  \n",
      "4          None  0.582702    0.241075    211  \n",
      "5          None -0.005619  224.016383   1789  \n",
      "6          None  0.000000    0.000000   2000  \n",
      "7          None  0.542929    0.237980    211  \n",
      "8          None -0.004151  222.895058   1789  \n",
      "9          None  0.000000    0.000000   2000  \n",
      "10         None  0.310711    0.681843    295  \n",
      "11         None -0.003388  222.111322   1705  \n",
      "12         None  0.000000    0.000000   2000  \n",
      "13         None  0.219178    1.252338    361  \n",
      "14         None -0.002044  220.742832   1639  \n",
      "15         None  0.000000    0.000000   2000  \n",
      "16         None  0.208623    1.246581    361  \n",
      "17         None -0.001388  220.211592   1639  \n",
      "18         None  0.000000    0.000000   2000  \n",
      "19         None  0.201692    1.243377    361  \n",
      "20         None -0.001403  220.171225   1639  \n",
      "21         None  0.000000    0.000000   2000  \n",
      "22         None  0.195420    1.240499    361  \n",
      "23         None -0.001568  220.236134   1639  \n",
      "24         None  0.000000    0.000000   2000  \n",
      "25         None -0.003274  191.704536   1907  \n",
      "26         None -0.036539   29.332951     93  \n",
      "27         None  0.000000    0.000000   2000  \n",
      "28         None -0.011020  187.106592   1907  \n",
      "29         None -0.032423   28.600740     93  \n",
      "    tree_index  node_depth node_index left_child right_child parent_index  \\\n",
      "0            0           1       0-S0       0-L0        0-L1         None   \n",
      "1            0           2       0-L0       None        None         0-S0   \n",
      "2            0           2       0-L1       None        None         0-S0   \n",
      "3            1           1       1-S0       1-L0        1-L1         None   \n",
      "4            1           2       1-L0       None        None         1-S0   \n",
      "5            1           2       1-L1       None        None         1-S0   \n",
      "6            2           1       2-S0       2-L0        2-L1         None   \n",
      "7            2           2       2-L0       None        None         2-S0   \n",
      "8            2           2       2-L1       None        None         2-S0   \n",
      "9            3           1       3-S0       3-L0        3-L1         None   \n",
      "10           3           2       3-L0       None        None         3-S0   \n",
      "11           3           2       3-L1       None        None         3-S0   \n",
      "12           4           1       4-S0       4-L0        4-L1         None   \n",
      "13           4           2       4-L0       None        None         4-S0   \n",
      "14           4           2       4-L1       None        None         4-S0   \n",
      "15           5           1       5-S0       5-L0        5-L1         None   \n",
      "16           5           2       5-L0       None        None         5-S0   \n",
      "17           5           2       5-L1       None        None         5-S0   \n",
      "18           6           1       6-S0       6-L0        6-L1         None   \n",
      "19           6           2       6-L0       None        None         6-S0   \n",
      "20           6           2       6-L1       None        None         6-S0   \n",
      "21           7           1       7-S0       7-L0        7-L1         None   \n",
      "22           7           2       7-L0       None        None         7-S0   \n",
      "23           7           2       7-L1       None        None         7-S0   \n",
      "24           8           1       8-S0       8-L0        8-L1         None   \n",
      "25           8           2       8-L0       None        None         8-S0   \n",
      "26           8           2       8-L1       None        None         8-S0   \n",
      "27           9           1       9-S0       9-L0        9-L1         None   \n",
      "28           9           2       9-L0       None        None         9-S0   \n",
      "29           9           2       9-L1       None        None         9-S0   \n",
      "\n",
      "   split_feature  split_gain  threshold decision_type missing_direction  \\\n",
      "0             f2   49.281502   0.115291            <=              left   \n",
      "1           None         NaN        NaN          None              None   \n",
      "2           None         NaN        NaN          None              None   \n",
      "3             f2   63.249401   0.175118            <=              left   \n",
      "4           None         NaN        NaN          None              None   \n",
      "5           None         NaN        NaN          None              None   \n",
      "6             f2   53.452900   0.175118            <=              left   \n",
      "7           None         NaN        NaN          None              None   \n",
      "8           None         NaN        NaN          None              None   \n",
      "9             f2   46.762299   0.175118            <=              left   \n",
      "10          None         NaN        NaN          None              None   \n",
      "11          None         NaN        NaN          None              None   \n",
      "12            f2   40.686100   0.186976            <=              left   \n",
      "13          None         NaN        NaN          None              None   \n",
      "14          None         NaN        NaN          None              None   \n",
      "15            f2   35.106602   0.186976            <=              left   \n",
      "16          None         NaN        NaN          None              None   \n",
      "17          None         NaN        NaN          None              None   \n",
      "18            f2   30.679300   0.186976            <=              left   \n",
      "19          None         NaN        NaN          None              None   \n",
      "20          None         NaN        NaN          None              None   \n",
      "21            f2   27.039200   0.332248            <=              left   \n",
      "22          None         NaN        NaN          None              None   \n",
      "23          None         NaN        NaN          None              None   \n",
      "24            f2   24.594101   0.510441            <=              left   \n",
      "25          None         NaN        NaN          None              None   \n",
      "26          None         NaN        NaN          None              None   \n",
      "27            f2   20.293699   0.510441            <=              left   \n",
      "28          None         NaN        NaN          None              None   \n",
      "29          None         NaN        NaN          None              None   \n",
      "\n",
      "   missing_type     value      weight  count  \n",
      "0          None  0.000000    0.000000   2000  \n",
      "1          None -1.174657    0.337891    232  \n",
      "2          None -0.033912  230.792500   1768  \n",
      "3          None  0.000000    0.000000   2000  \n",
      "4          None -0.696453    1.259289    364  \n",
      "5          None -0.014340  213.376575   1636  \n",
      "6          None  0.000000    0.000000   2000  \n",
      "7          None -0.630655    1.288601    364  \n",
      "8          None -0.015341  214.043562   1636  \n",
      "9          None  0.000000    0.000000   2000  \n",
      "10         None -0.585633    1.306430    364  \n",
      "11         None -0.014478  213.150261   1636  \n",
      "12         None  0.000000    0.000000   2000  \n",
      "13         None -0.490079    1.611840    390  \n",
      "14         None -0.014240  212.180974   1610  \n",
      "15         None  0.000000    0.000000   2000  \n",
      "16         None -0.452230    1.629576    390  \n",
      "17         None -0.013703  211.562282   1610  \n",
      "18         None  0.000000    0.000000   2000  \n",
      "19         None -0.421249    1.642152    390  \n",
      "20         None -0.012665  210.521320   1610  \n",
      "21         None  0.000000    0.000000   2000  \n",
      "22         None -0.175291    7.706107    647  \n",
      "23         None -0.015540  203.523108   1353  \n",
      "24         None  0.000000    0.000000   2000  \n",
      "25         None -0.073894   30.512923   1023  \n",
      "26         None -0.023167  180.755228    977  \n",
      "27         None  0.000000    0.000000   2000  \n",
      "28         None -0.062328   30.974972   1023  \n",
      "29         None -0.025213  182.521492    977  \n"
     ]
    }
   ],
   "source": [
    "for booster in LPMC_model_fully_trained.boosters:\n",
    "    try:\n",
    "        print(booster.trees_to_dataframe())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3103c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0. Boosting step: 1. Model terms: 1. Terms eligible: 4. Validation error: 2.11966.\n",
      "Fold: 0. Boosting step: 2. Model terms: 2. Terms eligible: 4. Validation error: 0.981173.\n",
      "Fold: 0. Boosting step: 3. Model terms: 2. Terms eligible: 4. Validation error: 0.483448.\n",
      "Fold: 0. Boosting step: 4. Model terms: 2. Terms eligible: 4. Validation error: 0.246372.\n",
      "Fold: 0. Boosting step: 5. Model terms: 3. Terms eligible: 4. Validation error: 0.143454.\n",
      "Fold: 0. Boosting step: 6. Model terms: 4. Terms eligible: 4. Validation error: 0.0880048.\n",
      "Fold: 0. Boosting step: 7. Model terms: 5. Terms eligible: 4. Validation error: 0.0594562.\n",
      "Fold: 0. Boosting step: 8. Model terms: 6. Terms eligible: 4. Validation error: 0.0446251.\n",
      "Fold: 0. Boosting step: 9. Model terms: 7. Terms eligible: 4. Validation error: 0.0361705.\n",
      "Fold: 0. Boosting step: 10. Model terms: 8. Terms eligible: 4. Validation error: 0.0309179.\n",
      "Fold: 0. Boosting step: 11. Model terms: 9. Terms eligible: 4. Validation error: 0.0279479.\n",
      "Fold: 0. Boosting step: 12. Model terms: 10. Terms eligible: 4. Validation error: 0.0256724.\n",
      "Fold: 0. Boosting step: 13. Model terms: 11. Terms eligible: 4. Validation error: 0.0238424.\n",
      "Fold: 0. Boosting step: 14. Model terms: 12. Terms eligible: 4. Validation error: 0.0225354.\n",
      "Fold: 0. Boosting step: 15. Model terms: 13. Terms eligible: 4. Validation error: 0.0207639.\n",
      "Fold: 0. Boosting step: 16. Model terms: 14. Terms eligible: 4. Validation error: 0.0196518.\n",
      "Fold: 0. Boosting step: 17. Model terms: 15. Terms eligible: 4. Validation error: 0.0186492.\n",
      "Fold: 0. Boosting step: 18. Model terms: 16. Terms eligible: 4. Validation error: 0.017478.\n",
      "Fold: 0. Boosting step: 19. Model terms: 17. Terms eligible: 4. Validation error: 0.016552.\n",
      "Fold: 0. Boosting step: 20. Model terms: 18. Terms eligible: 4. Validation error: 0.015629.\n",
      "Fold: 0. Boosting step: 21. Model terms: 19. Terms eligible: 4. Validation error: 0.0148779.\n",
      "Fold: 0. Boosting step: 22. Model terms: 20. Terms eligible: 4. Validation error: 0.014144.\n",
      "Fold: 0. Boosting step: 23. Model terms: 21. Terms eligible: 4. Validation error: 0.0135275.\n",
      "Fold: 0. Boosting step: 24. Model terms: 22. Terms eligible: 4. Validation error: 0.012991.\n",
      "Fold: 0. Boosting step: 25. Model terms: 23. Terms eligible: 4. Validation error: 0.0123946.\n",
      "Fold: 0. Boosting step: 26. Model terms: 24. Terms eligible: 4. Validation error: 0.0118863.\n",
      "Fold: 0. Boosting step: 27. Model terms: 25. Terms eligible: 4. Validation error: 0.0115481.\n",
      "Fold: 0. Boosting step: 28. Model terms: 25. Terms eligible: 4. Validation error: 0.0110302.\n",
      "Fold: 0. Boosting step: 29. Model terms: 26. Terms eligible: 4. Validation error: 0.010626.\n",
      "Fold: 0. Boosting step: 30. Model terms: 27. Terms eligible: 4. Validation error: 0.0101885.\n",
      "Fold: 0. Boosting step: 31. Model terms: 28. Terms eligible: 4. Validation error: 0.00986523.\n",
      "Fold: 0. Boosting step: 32. Model terms: 29. Terms eligible: 4. Validation error: 0.0095428.\n",
      "Fold: 0. Boosting step: 33. Model terms: 30. Terms eligible: 4. Validation error: 0.00914824.\n",
      "Fold: 0. Boosting step: 34. Model terms: 31. Terms eligible: 4. Validation error: 0.00892769.\n",
      "Fold: 0. Boosting step: 35. Model terms: 32. Terms eligible: 4. Validation error: 0.00862328.\n",
      "Fold: 0. Boosting step: 36. Model terms: 33. Terms eligible: 4. Validation error: 0.00832332.\n",
      "Fold: 0. Boosting step: 37. Model terms: 34. Terms eligible: 4. Validation error: 0.00810769.\n",
      "Fold: 0. Boosting step: 38. Model terms: 35. Terms eligible: 4. Validation error: 0.0078146.\n",
      "Fold: 0. Boosting step: 39. Model terms: 36. Terms eligible: 4. Validation error: 0.00759451.\n",
      "Fold: 0. Boosting step: 40. Model terms: 37. Terms eligible: 4. Validation error: 0.0073397.\n",
      "Fold: 0. Boosting step: 41. Model terms: 38. Terms eligible: 4. Validation error: 0.0071834.\n",
      "Fold: 0. Boosting step: 42. Model terms: 39. Terms eligible: 4. Validation error: 0.00702256.\n",
      "Fold: 0. Boosting step: 43. Model terms: 40. Terms eligible: 4. Validation error: 0.00679736.\n",
      "Fold: 0. Boosting step: 44. Model terms: 41. Terms eligible: 4. Validation error: 0.00660654.\n",
      "Fold: 0. Boosting step: 45. Model terms: 42. Terms eligible: 4. Validation error: 0.00640793.\n",
      "Fold: 0. Boosting step: 46. Model terms: 43. Terms eligible: 4. Validation error: 0.00626961.\n",
      "Fold: 0. Boosting step: 47. Model terms: 44. Terms eligible: 4. Validation error: 0.00610199.\n",
      "Fold: 0. Boosting step: 48. Model terms: 45. Terms eligible: 4. Validation error: 0.00594363.\n",
      "Fold: 0. Boosting step: 49. Model terms: 45. Terms eligible: 4. Validation error: 0.0058435.\n",
      "Fold: 0. Boosting step: 50. Model terms: 46. Terms eligible: 4. Validation error: 0.00568172.\n",
      "Fold: 0. Boosting step: 51. Model terms: 47. Terms eligible: 4. Validation error: 0.00557431.\n",
      "Fold: 0. Boosting step: 52. Model terms: 48. Terms eligible: 4. Validation error: 0.00543533.\n",
      "Fold: 0. Boosting step: 53. Model terms: 49. Terms eligible: 4. Validation error: 0.00531063.\n",
      "Fold: 0. Boosting step: 54. Model terms: 50. Terms eligible: 4. Validation error: 0.00518776.\n",
      "Fold: 0. Boosting step: 55. Model terms: 51. Terms eligible: 4. Validation error: 0.00510526.\n",
      "Fold: 0. Boosting step: 56. Model terms: 52. Terms eligible: 4. Validation error: 0.00502075.\n",
      "Fold: 0. Boosting step: 57. Model terms: 53. Terms eligible: 4. Validation error: 0.00490437.\n",
      "Fold: 0. Boosting step: 58. Model terms: 54. Terms eligible: 4. Validation error: 0.00480793.\n",
      "Fold: 0. Boosting step: 59. Model terms: 55. Terms eligible: 4. Validation error: 0.00470486.\n",
      "Fold: 0. Boosting step: 60. Model terms: 56. Terms eligible: 4. Validation error: 0.00463113.\n",
      "Fold: 0. Boosting step: 61. Model terms: 57. Terms eligible: 4. Validation error: 0.00454111.\n",
      "Fold: 0. Boosting step: 62. Model terms: 58. Terms eligible: 4. Validation error: 0.00447787.\n",
      "Fold: 0. Boosting step: 63. Model terms: 59. Terms eligible: 4. Validation error: 0.00439658.\n",
      "Fold: 0. Boosting step: 64. Model terms: 60. Terms eligible: 4. Validation error: 0.00430922.\n",
      "Fold: 0. Boosting step: 65. Model terms: 61. Terms eligible: 4. Validation error: 0.00425061.\n",
      "Fold: 0. Boosting step: 66. Model terms: 62. Terms eligible: 4. Validation error: 0.00417523.\n",
      "Fold: 0. Boosting step: 67. Model terms: 63. Terms eligible: 4. Validation error: 0.00412297.\n",
      "Fold: 0. Boosting step: 68. Model terms: 64. Terms eligible: 4. Validation error: 0.00405572.\n",
      "Fold: 0. Boosting step: 69. Model terms: 65. Terms eligible: 4. Validation error: 0.00398134.\n",
      "Fold: 0. Boosting step: 70. Model terms: 66. Terms eligible: 4. Validation error: 0.00394346.\n",
      "Fold: 0. Boosting step: 71. Model terms: 67. Terms eligible: 4. Validation error: 0.00388082.\n",
      "Fold: 0. Boosting step: 72. Model terms: 67. Terms eligible: 4. Validation error: 0.00383846.\n",
      "Fold: 0. Boosting step: 73. Model terms: 68. Terms eligible: 4. Validation error: 0.00378221.\n",
      "Fold: 0. Boosting step: 74. Model terms: 69. Terms eligible: 4. Validation error: 0.0037263.\n",
      "Fold: 0. Boosting step: 75. Model terms: 70. Terms eligible: 4. Validation error: 0.00367609.\n",
      "Fold: 0. Boosting step: 76. Model terms: 71. Terms eligible: 4. Validation error: 0.00364013.\n",
      "Fold: 0. Boosting step: 77. Model terms: 72. Terms eligible: 4. Validation error: 0.00361104.\n",
      "Fold: 0. Boosting step: 78. Model terms: 73. Terms eligible: 4. Validation error: 0.0035621.\n",
      "Fold: 0. Boosting step: 79. Model terms: 74. Terms eligible: 4. Validation error: 0.00352048.\n",
      "Fold: 0. Boosting step: 80. Model terms: 75. Terms eligible: 4. Validation error: 0.00347708.\n",
      "Fold: 0. Boosting step: 81. Model terms: 76. Terms eligible: 4. Validation error: 0.00344866.\n",
      "Fold: 0. Boosting step: 82. Model terms: 77. Terms eligible: 4. Validation error: 0.00341.\n",
      "Fold: 0. Boosting step: 83. Model terms: 78. Terms eligible: 4. Validation error: 0.0033852.\n",
      "Fold: 0. Boosting step: 84. Model terms: 78. Terms eligible: 4. Validation error: 0.00334875.\n",
      "Fold: 0. Boosting step: 85. Model terms: 79. Terms eligible: 4. Validation error: 0.0033112.\n",
      "Fold: 0. Boosting step: 86. Model terms: 80. Terms eligible: 4. Validation error: 0.00328865.\n",
      "Fold: 0. Boosting step: 87. Model terms: 81. Terms eligible: 4. Validation error: 0.00325565.\n",
      "Fold: 0. Boosting step: 88. Model terms: 82. Terms eligible: 4. Validation error: 0.0032349.\n",
      "Fold: 0. Boosting step: 89. Model terms: 83. Terms eligible: 4. Validation error: 0.0032043.\n",
      "Fold: 0. Boosting step: 90. Model terms: 84. Terms eligible: 4. Validation error: 0.00317172.\n",
      "Fold: 0. Boosting step: 91. Model terms: 85. Terms eligible: 4. Validation error: 0.00315738.\n",
      "Fold: 0. Boosting step: 92. Model terms: 86. Terms eligible: 4. Validation error: 0.00312943.\n",
      "Fold: 0. Boosting step: 93. Model terms: 87. Terms eligible: 4. Validation error: 0.00310464.\n",
      "Fold: 0. Boosting step: 94. Model terms: 87. Terms eligible: 4. Validation error: 0.00307812.\n",
      "Fold: 0. Boosting step: 95. Model terms: 88. Terms eligible: 4. Validation error: 0.00306081.\n",
      "Fold: 0. Boosting step: 96. Model terms: 89. Terms eligible: 4. Validation error: 0.00303332.\n",
      "Fold: 0. Boosting step: 97. Model terms: 89. Terms eligible: 4. Validation error: 0.00301768.\n",
      "Fold: 0. Boosting step: 98. Model terms: 90. Terms eligible: 4. Validation error: 0.0029922.\n",
      "Fold: 0. Boosting step: 99. Model terms: 91. Terms eligible: 4. Validation error: 0.00297067.\n",
      "Fold: 0. Boosting step: 100. Model terms: 91. Terms eligible: 4. Validation error: 0.00294631.\n",
      "Model terms: 91. Terms available in final boosting step: 4.\n",
      "Fold: 1. Boosting step: 1. Model terms: 1. Terms eligible: 4. Validation error: 2.11307.\n",
      "Fold: 1. Boosting step: 2. Model terms: 2. Terms eligible: 4. Validation error: 0.987567.\n",
      "Fold: 1. Boosting step: 3. Model terms: 3. Terms eligible: 4. Validation error: 0.478973.\n",
      "Fold: 1. Boosting step: 4. Model terms: 3. Terms eligible: 4. Validation error: 0.244304.\n",
      "Fold: 1. Boosting step: 5. Model terms: 3. Terms eligible: 4. Validation error: 0.141666.\n",
      "Fold: 1. Boosting step: 6. Model terms: 4. Terms eligible: 4. Validation error: 0.0930626.\n",
      "Fold: 1. Boosting step: 7. Model terms: 5. Terms eligible: 4. Validation error: 0.0640622.\n",
      "Fold: 1. Boosting step: 8. Model terms: 6. Terms eligible: 4. Validation error: 0.0500605.\n",
      "Fold: 1. Boosting step: 9. Model terms: 7. Terms eligible: 4. Validation error: 0.0405844.\n",
      "Fold: 1. Boosting step: 10. Model terms: 8. Terms eligible: 4. Validation error: 0.0354365.\n",
      "Fold: 1. Boosting step: 11. Model terms: 9. Terms eligible: 4. Validation error: 0.0315603.\n",
      "Fold: 1. Boosting step: 12. Model terms: 10. Terms eligible: 4. Validation error: 0.0292284.\n",
      "Fold: 1. Boosting step: 13. Model terms: 11. Terms eligible: 4. Validation error: 0.0271993.\n",
      "Fold: 1. Boosting step: 14. Model terms: 12. Terms eligible: 4. Validation error: 0.0253824.\n",
      "Fold: 1. Boosting step: 15. Model terms: 12. Terms eligible: 4. Validation error: 0.0237427.\n",
      "Fold: 1. Boosting step: 16. Model terms: 13. Terms eligible: 4. Validation error: 0.0222952.\n",
      "Fold: 1. Boosting step: 17. Model terms: 14. Terms eligible: 4. Validation error: 0.021031.\n",
      "Fold: 1. Boosting step: 18. Model terms: 14. Terms eligible: 4. Validation error: 0.0197692.\n",
      "Fold: 1. Boosting step: 19. Model terms: 15. Terms eligible: 4. Validation error: 0.0186318.\n",
      "Fold: 1. Boosting step: 20. Model terms: 16. Terms eligible: 4. Validation error: 0.0176232.\n",
      "Fold: 1. Boosting step: 21. Model terms: 17. Terms eligible: 4. Validation error: 0.0167403.\n",
      "Fold: 1. Boosting step: 22. Model terms: 18. Terms eligible: 4. Validation error: 0.0159283.\n",
      "Fold: 1. Boosting step: 23. Model terms: 19. Terms eligible: 4. Validation error: 0.0150484.\n",
      "Fold: 1. Boosting step: 24. Model terms: 20. Terms eligible: 4. Validation error: 0.0143628.\n",
      "Fold: 1. Boosting step: 25. Model terms: 21. Terms eligible: 4. Validation error: 0.0136845.\n",
      "Fold: 1. Boosting step: 26. Model terms: 22. Terms eligible: 4. Validation error: 0.0130549.\n",
      "Fold: 1. Boosting step: 27. Model terms: 23. Terms eligible: 4. Validation error: 0.0125748.\n",
      "Fold: 1. Boosting step: 28. Model terms: 24. Terms eligible: 4. Validation error: 0.0119707.\n",
      "Fold: 1. Boosting step: 29. Model terms: 25. Terms eligible: 4. Validation error: 0.0115468.\n",
      "Fold: 1. Boosting step: 30. Model terms: 26. Terms eligible: 4. Validation error: 0.0110403.\n",
      "Fold: 1. Boosting step: 31. Model terms: 27. Terms eligible: 4. Validation error: 0.0106189.\n",
      "Fold: 1. Boosting step: 32. Model terms: 28. Terms eligible: 4. Validation error: 0.0102268.\n",
      "Fold: 1. Boosting step: 33. Model terms: 29. Terms eligible: 4. Validation error: 0.00984213.\n",
      "Fold: 1. Boosting step: 34. Model terms: 30. Terms eligible: 4. Validation error: 0.00955087.\n",
      "Fold: 1. Boosting step: 35. Model terms: 31. Terms eligible: 4. Validation error: 0.00919601.\n",
      "Fold: 1. Boosting step: 36. Model terms: 32. Terms eligible: 4. Validation error: 0.00893103.\n",
      "Fold: 1. Boosting step: 37. Model terms: 33. Terms eligible: 4. Validation error: 0.00860778.\n",
      "Fold: 1. Boosting step: 38. Model terms: 34. Terms eligible: 4. Validation error: 0.00836425.\n",
      "Fold: 1. Boosting step: 39. Model terms: 35. Terms eligible: 4. Validation error: 0.00811083.\n",
      "Fold: 1. Boosting step: 40. Model terms: 36. Terms eligible: 4. Validation error: 0.00785961.\n",
      "Fold: 1. Boosting step: 41. Model terms: 37. Terms eligible: 4. Validation error: 0.00766853.\n",
      "Fold: 1. Boosting step: 42. Model terms: 38. Terms eligible: 4. Validation error: 0.00744836.\n",
      "Fold: 1. Boosting step: 43. Model terms: 39. Terms eligible: 4. Validation error: 0.00726676.\n",
      "Fold: 1. Boosting step: 44. Model terms: 40. Terms eligible: 4. Validation error: 0.00701537.\n",
      "Fold: 1. Boosting step: 45. Model terms: 41. Terms eligible: 4. Validation error: 0.0068562.\n",
      "Fold: 1. Boosting step: 46. Model terms: 42. Terms eligible: 4. Validation error: 0.00668008.\n",
      "Fold: 1. Boosting step: 47. Model terms: 43. Terms eligible: 4. Validation error: 0.00648868.\n",
      "Fold: 1. Boosting step: 48. Model terms: 44. Terms eligible: 4. Validation error: 0.00636074.\n",
      "Fold: 1. Boosting step: 49. Model terms: 45. Terms eligible: 4. Validation error: 0.006195.\n",
      "Fold: 1. Boosting step: 50. Model terms: 46. Terms eligible: 4. Validation error: 0.00607356.\n",
      "Fold: 1. Boosting step: 51. Model terms: 47. Terms eligible: 4. Validation error: 0.00594858.\n",
      "Fold: 1. Boosting step: 52. Model terms: 48. Terms eligible: 4. Validation error: 0.00578743.\n",
      "Fold: 1. Boosting step: 53. Model terms: 49. Terms eligible: 4. Validation error: 0.00566945.\n",
      "Fold: 1. Boosting step: 54. Model terms: 49. Terms eligible: 4. Validation error: 0.0055104.\n",
      "Fold: 1. Boosting step: 55. Model terms: 50. Terms eligible: 4. Validation error: 0.00541521.\n",
      "Fold: 1. Boosting step: 56. Model terms: 51. Terms eligible: 4. Validation error: 0.00530011.\n",
      "Fold: 1. Boosting step: 57. Model terms: 52. Terms eligible: 4. Validation error: 0.00520851.\n",
      "Fold: 1. Boosting step: 58. Model terms: 53. Terms eligible: 4. Validation error: 0.00510883.\n",
      "Fold: 1. Boosting step: 59. Model terms: 54. Terms eligible: 4. Validation error: 0.00499732.\n",
      "Fold: 1. Boosting step: 60. Model terms: 55. Terms eligible: 4. Validation error: 0.0049261.\n",
      "Fold: 1. Boosting step: 61. Model terms: 56. Terms eligible: 4. Validation error: 0.00483895.\n",
      "Fold: 1. Boosting step: 62. Model terms: 57. Terms eligible: 4. Validation error: 0.00472312.\n",
      "Fold: 1. Boosting step: 63. Model terms: 58. Terms eligible: 4. Validation error: 0.00464915.\n",
      "Fold: 1. Boosting step: 64. Model terms: 59. Terms eligible: 4. Validation error: 0.00456532.\n",
      "Fold: 1. Boosting step: 65. Model terms: 60. Terms eligible: 4. Validation error: 0.00448964.\n",
      "Fold: 1. Boosting step: 66. Model terms: 61. Terms eligible: 4. Validation error: 0.00442282.\n",
      "Fold: 1. Boosting step: 67. Model terms: 62. Terms eligible: 4. Validation error: 0.00435598.\n",
      "Fold: 1. Boosting step: 68. Model terms: 63. Terms eligible: 4. Validation error: 0.00429441.\n",
      "Fold: 1. Boosting step: 69. Model terms: 64. Terms eligible: 4. Validation error: 0.00421535.\n",
      "Fold: 1. Boosting step: 70. Model terms: 65. Terms eligible: 4. Validation error: 0.00416785.\n",
      "Fold: 1. Boosting step: 71. Model terms: 66. Terms eligible: 4. Validation error: 0.00410768.\n",
      "Fold: 1. Boosting step: 72. Model terms: 66. Terms eligible: 4. Validation error: 0.0040297.\n",
      "Fold: 1. Boosting step: 73. Model terms: 67. Terms eligible: 4. Validation error: 0.0039865.\n",
      "Fold: 1. Boosting step: 74. Model terms: 68. Terms eligible: 4. Validation error: 0.00393808.\n",
      "Fold: 1. Boosting step: 75. Model terms: 69. Terms eligible: 4. Validation error: 0.00387992.\n",
      "Fold: 1. Boosting step: 76. Model terms: 70. Terms eligible: 4. Validation error: 0.0038352.\n",
      "Fold: 1. Boosting step: 77. Model terms: 70. Terms eligible: 4. Validation error: 0.00378958.\n",
      "Fold: 1. Boosting step: 78. Model terms: 71. Terms eligible: 4. Validation error: 0.00374813.\n",
      "Fold: 1. Boosting step: 79. Model terms: 72. Terms eligible: 4. Validation error: 0.00369346.\n",
      "Fold: 1. Boosting step: 80. Model terms: 73. Terms eligible: 4. Validation error: 0.0036618.\n",
      "Fold: 1. Boosting step: 81. Model terms: 74. Terms eligible: 4. Validation error: 0.00362093.\n",
      "Fold: 1. Boosting step: 82. Model terms: 75. Terms eligible: 4. Validation error: 0.00356696.\n",
      "Fold: 1. Boosting step: 83. Model terms: 75. Terms eligible: 4. Validation error: 0.00353764.\n",
      "Fold: 1. Boosting step: 84. Model terms: 75. Terms eligible: 4. Validation error: 0.00350522.\n",
      "Fold: 1. Boosting step: 85. Model terms: 76. Terms eligible: 4. Validation error: 0.00347579.\n",
      "Fold: 1. Boosting step: 86. Model terms: 77. Terms eligible: 4. Validation error: 0.00343574.\n",
      "Fold: 1. Boosting step: 87. Model terms: 77. Terms eligible: 4. Validation error: 0.00340478.\n",
      "Fold: 1. Boosting step: 88. Model terms: 78. Terms eligible: 4. Validation error: 0.00337595.\n",
      "Fold: 1. Boosting step: 89. Model terms: 79. Terms eligible: 4. Validation error: 0.00333745.\n",
      "Fold: 1. Boosting step: 90. Model terms: 80. Terms eligible: 4. Validation error: 0.00331632.\n",
      "Fold: 1. Boosting step: 91. Model terms: 81. Terms eligible: 4. Validation error: 0.00328794.\n",
      "Fold: 1. Boosting step: 92. Model terms: 82. Terms eligible: 4. Validation error: 0.00325007.\n",
      "Fold: 1. Boosting step: 93. Model terms: 83. Terms eligible: 4. Validation error: 0.00322976.\n",
      "Fold: 1. Boosting step: 94. Model terms: 84. Terms eligible: 4. Validation error: 0.00320391.\n",
      "Fold: 1. Boosting step: 95. Model terms: 84. Terms eligible: 4. Validation error: 0.0031841.\n",
      "Fold: 1. Boosting step: 96. Model terms: 84. Terms eligible: 4. Validation error: 0.00316227.\n",
      "Fold: 1. Boosting step: 97. Model terms: 84. Terms eligible: 4. Validation error: 0.00313431.\n",
      "Fold: 1. Boosting step: 98. Model terms: 85. Terms eligible: 4. Validation error: 0.0031138.\n",
      "Fold: 1. Boosting step: 99. Model terms: 86. Terms eligible: 4. Validation error: 0.00309134.\n",
      "Fold: 1. Boosting step: 100. Model terms: 87. Terms eligible: 4. Validation error: 0.00307236.\n",
      "Model terms: 87. Terms available in final boosting step: 4.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from interpret.glassbox import APLRClassifier, ExplainableBoostingClassifier, APLRRegressor\n",
    "from lightgbm import train\n",
    "model_aplr = APLRRegressor(random_state=1, m=100, max_interaction_level=0, verbosity=2, min_observations_in_split=1, v = 0.2, bins=2000, cv_folds=2)\n",
    "# model_aplr = ExplainableBoostingClassifier(random_state=42)\n",
    "model_aplr.fit(dataset[features].values, dataset[\"choice\"], X_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f1ab466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.002857116017656334\n"
     ]
    }
   ],
   "source": [
    "from rumboost.metrics import cross_entropy\n",
    "# preds = model_aplr.predict_class_probabilities(dataset_test[features[0]].values)\n",
    "if n_utility > 1:\n",
    "    preds = model_aplr.predict_proba(dataset_test[features].values)\n",
    "    print(cross_entropy(preds, dataset_test[\"choice\"].astype(int).values))\n",
    "else:\n",
    "    preds = model_aplr.predict(dataset_test[features].values)\n",
    "    mse = np.mean((preds - dataset_test[\"choice\"].values)**2)\n",
    "    print(f\"Mean squared error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3f412ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/127067092303632/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/127067092303632/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from interpret import show\n",
    "show(model_aplr.explain_global())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ca1318f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x73911efe5610>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train_set.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70d163fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  3,  2,  2,  3,  9,  3,  1,  6,  9,  0,  5,  0,  4,  6,  0, 17,\n",
       "         9,  3,  0,  3,  8,  0,  0,  2,  0,  0,  0,  1]),\n",
       " array([0.02168464, 0.04405916, 0.06643367, 0.08880818, 0.1111827 ,\n",
       "        0.13355721, 0.15593172, 0.17830624, 0.20068075, 0.22305526,\n",
       "        0.24542978, 0.26780429, 0.2901788 , 0.31255332, 0.33492783,\n",
       "        0.35730234, 0.37967686, 0.40205137, 0.42442588, 0.44680039,\n",
       "        0.46917491, 0.49154942, 0.51392393, 0.53629845, 0.55867296,\n",
       "        0.58104747, 0.60342199, 0.6257965 , 0.64817101, 0.67054553]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LPMC_model_fully_trained.boosters[0].get_split_value_histogram(\"f0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class LinearTree:\n",
    "    def __init__(self, x, monotonic_constraint = 0, max_bins=255):\n",
    "        \"\"\" x must be 1d shape\"\"\"\n",
    "        self.bin_edges, self.histograms, self.bin_indices = self.build_lightgbm_style_histogram(x, max_bins)\n",
    "        self.bin_indices = self.bin_indices.reshape(1, -1).repeat(self.bin_edges.shape[0], axis=0)\n",
    "        self.x = x\n",
    "        self.monotonic_constraint = monotonic_constraint\n",
    "        self.upper_bound = 0\n",
    "        self.lower_bound = 0\n",
    "        self.x_minus_bin_edges = self.x[None, :] - self.bin_edges[1:-1, None] \n",
    "        self.split_and_leaf_values = {\n",
    "                        \"splits\": np.array([x.min(), x.max()]),\n",
    "                        \"constants\": np.array([0.0, 0.0]),\n",
    "                        \"leaves\": np.array([0.0]),\n",
    "                        \"value_at_splits\": np.array([0.0, 0.0]),\n",
    "                    }\n",
    "        self.feature_importance = {\"gain\": np.array([])}\n",
    "        # x_0 - e_0, x_0 - e_1, ...\n",
    "        # x_1 - e_0, x_1 - e_1, ...\n",
    "\n",
    "\n",
    "    def build_lightgbm_style_histogram(feature_values, max_bins=255):\n",
    "\n",
    "        percentiles = np.linspace(0, 100, max_bins + 1)\n",
    "        bin_edges = np.unique(np.percentile(feature_values, percentiles))\n",
    "\n",
    "        bin_indices = np.digitize(feature_values, bins=bin_edges[1:-1], right=True)\n",
    "\n",
    "        histogram = np.bincount(bin_indices, minlength=len(bin_edges) - 1)\n",
    "\n",
    "        return bin_edges, histogram, bin_indices\n",
    "\n",
    "    def update(self, _, fobj):\n",
    "\n",
    "        grad, hess = fobj(_, _)\n",
    "        grad_x = grad * self.x_minus_bin_edges\n",
    "        hess_x = hess * self.x_minus_bin_edges\n",
    "\n",
    "        N = self.bin_indices.max()+1\n",
    "        id = self.bin_indices + (N*np.arange(self.bin_indices.shape[0]))[:,None]\n",
    "\n",
    "        grad_x_binned = np.bincount(id.ravel(), weights=grad_x.ravel()).reshape(-1, N)\n",
    "        hess_x_binned = np.bincount(id.ravel(), weights=hess_x.ravel()).reshape(-1, N)\n",
    "\n",
    "        arange = np.arange(grad_x_binned.shape[0])\n",
    "        edgerange = np.arange(grad_x_binned.shape[0]-1) + 1\n",
    "        mask = arange[None, :] < edgerange[:, None]\n",
    "\n",
    "        left_gain = grad_x_binned[mask].sum(axis=0) ** 2 / hess_x_binned[mask].sum(axis=0)\n",
    "        left_leaf = - grad_x_binned[mask].sum(axis=0) / hess_x_binned[mask].sum(axis=0)\n",
    "\n",
    "        right_gain = grad_x_binned[~mask].sum(axis=0) ** 2 / hess_x_binned[~mask].sum(axis=0)\n",
    "        right_leaf = - grad_x_binned[~mask].sum(axis=0) / hess_x_binned[~mask].sum(axis=0)\n",
    "\n",
    "        no_split_gain = grad_x_binned.sum() / hess_x_binned.sum()\n",
    "\n",
    "        if self.monotonic_constraint == 1:\n",
    "            left_gain[left_leaf < self.lower_bound] = -np.inf\n",
    "            right_gain[right_leaf < self.lower_bound] = -np.inf\n",
    "        \n",
    "        if self.monotonic_constraint == -1:\n",
    "            left_gain[left_leaf > self.upper_bound] = -np.inf\n",
    "            right_gain[right_leaf > self.upper_bound] = -np.inf\n",
    "\n",
    "        gain = left_gain + right_gain - no_split_gain\n",
    "\n",
    "        best_index = np.argmax(gain)\n",
    "        best_threshold = self.bin_edges[best_index+1]\n",
    "        best_left_leaf = left_leaf[best_index]\n",
    "        best_right_leaf = right_leaf[best_index]\n",
    "        best_gain = gain[best_index]\n",
    "        self.feature_importance[\"gain\"].append(best_gain)\n",
    "\n",
    "        self._update_linear_constants(best_threshold, (best_left_leaf, best_right_leaf))\n",
    "\n",
    "    def _update_linear_constants(self, split_values, leaf_values):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        s = split_values\n",
    "        l_0 = leaf_values[0]\n",
    "        l_1 = leaf_values[1]\n",
    "        if (\n",
    "            s in self.split_and_leaf_values[\"splits\"]\n",
    "        ):  # if the split value exists already\n",
    "            index = np.searchsorted(self.split_and_leaf_values[\"splits\"], s)\n",
    "            self.split_and_leaf_values[\"leaves\"][:index] += l_0\n",
    "\n",
    "            self.split_and_leaf_values[\"leaves\"][index:] += l_1\n",
    "\n",
    "            self.split_and_leaf_values[\"constants\"] = np.concatenate(\n",
    "                (\n",
    "                    self.split_and_leaf_values[\"constants\"][: index + 1]\n",
    "                    + l_1 * s, \n",
    "                    self.split_and_leaf_values[\"constants\"][index + 1 :]\n",
    "                    + l_0 * s,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            index = np.searchsorted(self.split_and_leaf_values[\"splits\"], s)\n",
    "            self.split_and_leaf_values[\"splits\"] = np.insert(\n",
    "                self.split_and_leaf_values[\"splits\"], index, s\n",
    "            )\n",
    "\n",
    "            self.split_and_leaf_values[\"leaves\"] = np.concatenate(\n",
    "                (\n",
    "                    self.split_and_leaf_values[\"leaves\"][:index] + l_0,\n",
    "                    self.split_and_leaf_values[\"leaves\"][index - 1 :] + l_1,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.split_and_leaf_values[\"constants\"] = np.concatenate(\n",
    "                (\n",
    "                    self.split_and_leaf_values[\"constants\"][: index + 1]\n",
    "                    + l_1 * s,\n",
    "                    self.split_and_leaf_values[\"constants\"][index:]\n",
    "                    + l_0 * s,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.upper_bound = np.max(self.split_and_leaf_values[\"leaves\"])\n",
    "        self.lower_bound = np.min(self.split_and_leaf_values[\"leaves\"])\n",
    "\n",
    "        leaves = self.split_and_leaf_values[\"leaves\"]\n",
    "        splits = self.split_and_leaf_values[\"splits\"]\n",
    "        all_leaves = np.concatenate((leaves[0].reshape(-1), leaves))\n",
    "        constants = self.split_and_leaf_values[\"constants\"]\n",
    "\n",
    "        self.split_and_leaf_values[\"value_at_splits\"] = (\n",
    "            all_leaves * splits + constants\n",
    "        )\n",
    "    \n",
    "    def eval_train(self, feval):\n",
    "        pass\n",
    "\n",
    "    def eval_valid(self, feval):\n",
    "        pass\n",
    "\n",
    "    def model_to_string(self, _, __, ___) -> str:\n",
    "        \"\"\"\n",
    "        Serialize the model to a JSON string.\n",
    "        \"\"\"\n",
    "        model_dict = {\n",
    "            \"bin_edges\": self.bin_edges.tolist(),\n",
    "            \"histograms\": self.histograms.tolist(),\n",
    "            \"split_and_leaf_values\": {\n",
    "                k: v.tolist() for k, v in self.split_and_leaf_values.items()\n",
    "            },\n",
    "            \"monotonic_constraint\": self.monotonic_constraint,\n",
    "            \"upper_bound\": self.upper_bound,\n",
    "            \"lower_bound\": self.lower_bound,\n",
    "            \"feature_importance\": self.feature_importance\n",
    "        }\n",
    "        return json.dumps(model_dict)\n",
    "\n",
    "    def model_from_string(self, s: str):\n",
    "        \"\"\"\n",
    "        Load the model from a JSON string.\n",
    "        \"\"\"\n",
    "        model_dict = json.loads(s)\n",
    "        self.bin_edges = np.array(model_dict[\"bin_edges\"])\n",
    "        self.histograms = np.array(model_dict[\"histograms\"])\n",
    "        self.split_and_leaf_values = {\n",
    "            k: np.array(v) for k, v in model_dict[\"split_and_leaf_values\"].items()\n",
    "        }\n",
    "        self.monotonic_constraint = model_dict[\"monotonic_constraint\"]\n",
    "        self.upper_bound = model_dict[\"upper_bound\"]\n",
    "        self.lower_bound = model_dict[\"lower_bound\"]\n",
    "        self.feature_importance = model_dict[\"feature_importance\"]\n",
    "\n",
    "    def free_dataset(self,):\n",
    "        self.x = None\n",
    "\n",
    "    def set_train_data_name(self, name: str) -> \"LinearTree\":\n",
    "        \"\"\"Set the name to the training Dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name for the training Dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : Booster\n",
    "            Booster with set training Dataset name.\n",
    "        \"\"\"\n",
    "        self._train_data_name = name\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4abf3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2, 1]).reshape(1, -1)\n",
    "a = a.repeat(3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d586df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_x = np.array([[1, 2, 3], [2, 1, 1], [0, 0, 0], [10, -1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b75e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1],\n",
       "       [0, 1, 2, 1],\n",
       "       [0, 1, 2, 1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65960d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1],\n",
       "       [3, 4, 5, 4],\n",
       "       [6, 7, 8, 7]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "080b0a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bec51e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  2,  1,  1,  0,  0,  0, 10, -1,  2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_x.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b59f4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = np.bincount(id.ravel(), weights=grad_x.ravel()).reshape(-1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31505035",
   "metadata": {},
   "outputs": [],
   "source": [
    "arange = np.arange(bb.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe75746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80ceda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "asquare = arange.reshape(1, -1).repeat(bb.shape[1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "674f14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arange = np.arange(10)\n",
    "edgerange = np.arange(9) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e79a249d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False, False, False,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False, False, False, False, False,  True,  True,  True,\n",
       "         True],\n",
       "       [False, False, False, False, False, False, False,  True,  True,\n",
       "         True],\n",
       "       [False, False, False, False, False, False, False, False,  True,\n",
       "         True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "         True]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~(arange[None, :] < edgerange[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5741d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rumb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
